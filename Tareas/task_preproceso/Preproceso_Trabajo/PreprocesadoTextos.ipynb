{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocesadoTextos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mj-ks6fqT25"
      },
      "source": [
        " # Todas las cuestiones relativas al preprocesado figuran en este Collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrsy19b21q6J"
      },
      "source": [
        "#### **Recordatorio**: aunque todo este preprocesado se haya hecho en grupo, se recuerda que la redacci√≥n ha de ser personalizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73QBKRpzqasp"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Length Features\n",
        "\n",
        "Aqu√≠ se recogen algunas variables relacionadas con la longitud de la frase tanto a nivel de token como a nivel de caracter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPxleGp6p6BH"
      },
      "source": [
        "import pandas as pd\n",
        "train_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/haha_2021_train.csv\", sep=',')"
      ],
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0P3h2Zvqxqz"
      },
      "source": [
        "text = train_dataframe[['text']]\n",
        "text = text.iloc[0:10,:]"
      ],
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_YWgPaW5qswt",
        "outputId": "8c2d661a-882a-4116-c796-99a8996173c5"
      },
      "source": [
        "def len_token(tweet):\n",
        "  tweet_tokens = tweet.replace('\\n', ' ').split(' ')\n",
        "  return len(tweet_tokens)\n",
        "def n_characters_tweet(tweet):\n",
        "  tweet = tweet.replace('\\n', ' ')\n",
        "  return len(tweet)\n",
        "\n",
        "def get_len_token(text):\n",
        "  return list(map(len_token, text['text'].to_list()))\n",
        "\n",
        "def get_n_characters_tweet(text):\n",
        "  return list(map(n_characters_tweet, text['text'].to_list()))\n",
        "\n",
        "def get_n_characters_tweet(text):\n",
        "  return list(map(n_characters_tweet, text['text'].to_list()))\n",
        "\n",
        "text['len_token'] = get_len_token(text)\n",
        "\n",
        "text['n_char'] = get_n_characters_tweet(text)\n",
        "\n",
        "text['ratio'] = text['len_token']/text['n_char']\n",
        "\n",
        "text"
      ],
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqu√© me hago la cabeza deooos</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...     ratio\n",
              "0  Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...  ...  0.220930\n",
              "1  ‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...  ...  0.157143\n",
              "2  - ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...  ...  0.187500\n",
              "3              No se porqu√© me hago la cabeza deooos  ...  0.216216\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...  0.188679\n",
              "5  La persona que te dice que no se arrepiente de...  ...  0.216667\n",
              "6  ‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...  ...  0.169643\n",
              "7                                       Meeee aburro  ...  0.166667\n",
              "8  Macri le dijo las gordas que usar calzas est√° ...  ...  0.196078\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...  0.137931\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvNuLb2w-5ZD"
      },
      "source": [
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNvKkoiBPAN"
      },
      "source": [
        "# Detector de cansinos y correcci√≥n de repeticiones innecesarias\n",
        "\n",
        "En twitter hay mucho \"pesao\" con el pulgar \"cansao\" y lo dejan mucho tiempo en el m√≥ooooooooovil pulsando una letraaaaa. A todos estos, los consideramos unos pesaos y lo vamos a tener en cuenta. No quieren trabajar.\n",
        "\n",
        "¬øPor qu√© corregiremos tambi√©n a los pesaos? Porque spellchecker no puede, es f√°cil ver esto con un ejemplo en c√≥digo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7I8k8XfG-7M3",
        "outputId": "6db519d4-b9c5-4c0b-c541-769b045f69de"
      },
      "source": [
        "def is_cansino(tweet, tolerancia:int=2):\n",
        "  # Consideramos pesados a todos aquellos\n",
        "  # que repitan 3 veces una letra\n",
        "  \"\"\"\n",
        "  Esta funci√≥n identifica a los pesaos\n",
        "  Args:\n",
        "    tolerancia (int): tolerancia al pesao\n",
        "  \"\"\"\n",
        "  l1 = \"\"\n",
        "  rep = 0\n",
        "  for index, letra in enumerate(tweet):\n",
        "      if letra == l1:\n",
        "          rep += 1\n",
        "      elif rep >= tolerancia:\n",
        "          return l1, rep, tolerancia, 1*True\n",
        "      else:\n",
        "        rep = 0\n",
        "        l1 = letra\n",
        "  return letra, 0, tolerancia, 1*False\n",
        "\n",
        "def get_cansinos(corpus):\n",
        "  L = list(map(is_cansino, corpus))\n",
        "  return [ret[3] for ret in L]\n",
        "\n",
        "###################################\n",
        "##### Correccion repeticiones #####\n",
        "###################################\n",
        "\n",
        "# Esto es beta solo corrige la primera\n",
        "# tanda de repeticiones se puede mejorar\n",
        "\n",
        "def tweet_corrector(tweet):\n",
        "    letra, rep, tolerancia, bool_ = is_cansino(tweet)\n",
        "    if bool_ == 1:\n",
        "        tweet = tweet.replace(rep*letra, '')\n",
        "    return tweet\n",
        "\n",
        "def corpus_corrector(corpus):\n",
        "    L = list(map(tweet_corrector, corpus))\n",
        "    return L\n",
        "\n",
        "text['detected_cansinos'] = get_cansinos(text['text'].to_list())\n",
        "\n",
        "text['text_v2'] = corpus_corrector(text['text'].to_list())\n",
        "\n",
        "text"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>text_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqu√© me hago la cabeza deooos</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "      <td>No se porqu√© me hago la cabeza deos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0</td>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "      <td>0</td>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1</td>\n",
              "      <td>Me aburro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0</td>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                            text_v2\n",
              "0  Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...  ...  Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...\n",
              "1  ‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...  ...  ‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...\n",
              "2  - ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...  ...  - ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...\n",
              "3              No se porqu√© me hago la cabeza deooos  ...                No se porqu√© me hago la cabeza deos\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...  Quisiera saber que hago durante la siesta de l...\n",
              "5  La persona que te dice que no se arrepiente de...  ...  La persona que te dice que no se arrepiente de...\n",
              "6  ‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...  ...  ‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...\n",
              "7                                       Meeee aburro  ...                                          Me aburro\n",
              "8  Macri le dijo las gordas que usar calzas est√° ...  ...  Macri le dijo las gordas que usar calzas est√° ...\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...                      JAVIER CHICALITO HERNANDEZ *7\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPp8qqtHNHRV"
      },
      "source": [
        ""
      ],
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RnLPsA9_WmOb",
        "outputId": "69877865-05f3-4e99-f679-5dc340655c46"
      },
      "source": [
        "count = 3\n",
        "string = 'holaaaa'\n",
        "string.replace(count*'a', '')"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hola'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8km82u1ang5"
      },
      "source": [
        "## **warning** ME he dado cuenta de esto antes de irme a dormir CUIDADOOOOOOOOOO perdemos la frecuencia de los emojisssssssssssssss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HYbqUM8AaegB",
        "outputId": "b01c2a4d-53c1-4e09-cb1d-9ae51486f7e4"
      },
      "source": [
        "string = \"üòÇüòÇüòÇüòÇ\"\n",
        "string.replace(\"üòÇ\"*3, '')"
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'üòÇ'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5mKE0s-Iwyi"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# SpellChecker (Corrector ortogr√°fico)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4NFs9wbJUOh"
      },
      "source": [
        "# SpellChecker creo que no hace falta, pero por si acaso la dejo\n",
        "# !pip install SpellChecker"
      ],
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqRUmrkeJS24"
      },
      "source": [
        "# pyspellchecker si hace falta instalarla\n",
        "# !pip install pyspellchecker\n",
        "from spellchecker import SpellChecker"
      ],
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CZcxEdQYJADg",
        "outputId": "3626d5e8-3729-4411-8c32-c46053234417"
      },
      "source": [
        "spell_check  = SpellChecker(language='es', distance=100)\n",
        "spell_check.correction(\"chicxs\")"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'chicos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 462
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg40bU_6q_0a"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Word Emoji Context Matrix. ü§£ üòÜ üòÇ \n",
        "\n",
        "Descripci√≥n: Extracci√≥n/guardado de Emojis y depuraci√≥n del Corpus\n",
        "\n",
        "Inconvenientes detectados con los emojis:\n",
        "\n",
        "* 1 Resulta que los emojis hemos podido verificar que countvectorizer los ignora. Es decir si las frases fueran solo emojis el shape de la matriz word context ser√≠a (1,1), con valor empty.\n",
        "\n",
        "* 2 Aun suponiendo que exista alguna alternativa a countvectorizer muchas personas escriben palabras juntas con emojis, e.g.: 'manüë®', lo que podr√≠a generar un token m√°s del vocabulario que innecesario. Adem√°s pueden escribir varios emojis juntos üë®, üë®üë®, üë®üë®üë®, ... generando tambi√©n un problema en su identificaci√≥n.\n",
        "\n",
        "La propuesta ha sido realizar un preproceso como el siguiente. Adem√°s, para solucionar el problema de los emoticonos, en lugar de pas√°rselos a countvectorizer en bruto utilizamos la decodificaci√≥n a texto de la librer√≠a emoji: **emoji.demojize()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIiT0DQFr7-D"
      },
      "source": [
        "# %%capture\n",
        "# !pip install emoji"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fZg102qqy3x"
      },
      "source": [
        "import emoji"
      ],
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtV7mIUrxI6"
      },
      "source": [
        "def extract_emojis(tweet):\n",
        "  return ''.join(c for c in tweet if c in emoji.UNICODE_EMOJI_ENGLISH)\n",
        "\n",
        "def get_emojilist(tweet):\n",
        "  emojistring = extract_emojis(tweet)\n",
        "  emojilist = [emoji for emoji in emojistring]\n",
        "  for emoji in emojilist:\n",
        "    tweet = tweet.replace(emoji, \"\")\n",
        "  return tweet, emojilist\n",
        "\n",
        "def get_emoji_sentence(tweet):\n",
        "  tweet, emojilist = get_emojilist(tweet)\n",
        "  emoji_sentence = emoji.demojize(' '.join(emojilist))\n",
        "  return tweet, emoji_sentence\n",
        "\n",
        "def filter(text_df):\n",
        "  filtered_df = pd.DataFrame(map(get_emoji_sentence, text_df['text_v2'].to_list()))\n",
        "  filtered_df.rename(columns={0: 'sentences_without_emojis', 1: 'emoji_sentences'}, inplace=True)\n",
        "  return filtered_df\n",
        "\n",
        "df_filter_output = filter(text)\n",
        "\n",
        "df_cleaned_sentences = df_filter_output[['sentences_without_emojis']]\n",
        "emoji_sentences = df_filter_output['emoji_sentences']\n",
        "\n",
        "def get_emoji_vocab(emoji_sentence):\n",
        "  analyzer = CountVectorizer(binary=False, analyzer='word', # stop_words=more_stop_words,\n",
        "                              ngram_range=(1, 1)).build_analyzer()\n",
        "  return (emoji for emoji in analyzer(emoji_sentence))"
      ],
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHBFHP-dsILP"
      },
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer\n",
        "cv_emoji = CountVectorizer(analyzer=get_emoji_vocab)"
      ],
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXpdsPjBsOR0"
      },
      "source": [
        "try:\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "# Just if there is no emoji\n",
        "except ValueError:\n",
        "  emoji_sentences.loc[0,0] = emoji.demojize(\"üÜò\")\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "# cv_emoji.get_feature_names()"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGX1lnvAZLzh",
        "outputId": "40e0cba0-a9fb-4b86-f116-83469b185310"
      },
      "source": [
        "cv_emoji.get_feature_names()"
      ],
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos_button']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 480
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAHq7-UxsXQk"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Obtenci√≥n de Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wIzMFmFsSL0"
      },
      "source": [
        "# %%capture\n",
        "# !pip install stop_words"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkMEdYs0scJi",
        "outputId": "987668f4-0832-413a-f3a0-880a2f836ba8"
      },
      "source": [
        "from stop_words import get_stop_words # Se a√±ade librer√≠a para obtener las stop_word de cualquier idioma\n",
        "!wget \"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\"\n",
        "\n",
        "# Se obtienen las stop_words en espa√±ol\n",
        "import pickle\n",
        "with open(\"more_stop_words.txt\", \"rb\") as f:\n",
        "  list_test = pickle.load(f)\n",
        "\n",
        "stop_words = get_stop_words(\"spanish\")\n",
        "more_stop_words = stop_words + list_test\n",
        "more_stop_words.sort()"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 23:59:36--  https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10258 (10K) [application/octet-stream]\n",
            "Saving to: ‚Äòmore_stop_words.txt.8‚Äô\n",
            "\n",
            "\rmore_stop_words.txt   0%[                    ]       0  --.-KB/s               \rmore_stop_words.txt 100%[===================>]  10.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-21 23:59:36 (62.6 MB/s) - ‚Äòmore_stop_words.txt.8‚Äô saved [10258/10258]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plCYOpqytS6q"
      },
      "source": [
        "# ELIMINACI√ìN DE IDIOMAS ALEJADOS DEL ESPA√ëOL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwRexGeKt7Zo"
      },
      "source": [
        "# !pip install spacy_langdetect"
      ],
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hlWpW9kyD8n"
      },
      "source": [
        "# frase de prueba\n",
        "# text = '¬øHola c√≥mo ÿ≥ŸÖÿ®ÿ£ÿ≥ŸÉŸÖŸÇ est√°is? Ï¢ÖÌòÑÏïÑÏÉùÏùºÏ∂ïÌïòÌï¥'"
      ],
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsY5GPpMta-e",
        "outputId": "b95797f3-d6cb-46cf-e0a3-332fed38a996"
      },
      "source": [
        "import spacy\n",
        "from spacy_langdetect import LanguageDetector\n",
        "\n",
        "# sentence level language detection\n",
        "dict_ = {}\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "\n",
        "# Eliminamos palabras koreanas, vietnamitas, japonesas o √°rabes\n",
        "L = ['ko', 'vi', 'ja', 'ar']\n",
        "df_cleaned_sentences_list = df_cleaned_sentences['sentences_without_emojis'].to_list()\n",
        "for index, sentence in enumerate(df_cleaned_sentences_list):\n",
        "  doc = nlp(sentence)\n",
        "  for subsent in doc.sents:\n",
        "    if subsent._.language['language'] in L:\n",
        "      df_cleaned_sentences_list[index] = sentence.replace(subsent.text,'')\n",
        "df_cleaned_sentences_list"
      ],
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medio.\\n‚Äî Alto.\\n‚Äî Elevado.\\n‚Äî Regresar con tu ex.',\n",
              " '‚ÄîVamos Luke desenfunda tu sable, demuestra tu odio, que perteneces al lado oscuro\\n‚ÄîSe√±or s√∫base los pantalones o llamo a seguridad.\\n‚ÄîJAJAJA.',\n",
              " '- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, mi vida entera?\\n-Agua est√° bien\\n-Pero yo cre√≠ que.\\n- ¬°AGUA DIJE!',\n",
              " 'No se porqu√© me hago la cabeza deos',\n",
              " 'Quisiera saber que hago durante la siesta de la cual me levanto m√°s cansado que cuando me acost√© a dormir.',\n",
              " 'La persona que te dice que no se arrepiente de nada en la vida, o no toma alcohol, o no lleva el celular cuando lo hace.',\n",
              " '‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?\\n‚Äî¬øEntera?\\n‚ÄîNo, si quiere t√≥mese un vasito pinche viejo abusivo...',\n",
              " 'Me aburro',\n",
              " 'Macri le dijo las gordas que usar calzas est√° bien.',\n",
              " 'JAVIER CHICALITO HERNANDEZ *7']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db8Z3XeEyfj1"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# CREACION MATRIZ WORD CONTEXT DEL TEXTO DEPURADO (SIN EMOJIS y sin idiomas poco habituales)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3HmJbsGtz7a",
        "outputId": "162e4312-b31e-4e09-87a7-28f675685a5e"
      },
      "source": [
        "from nltk.stem.snowball import SpanishStemmer\n",
        "def spanish_stemmer(sentence):\n",
        "    stemmer = SpanishStemmer()\n",
        "    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=more_stop_words,\n",
        "                               ngram_range=(1, 1)).build_analyzer()\n",
        "    return (stemmer.stem(word) for word in analyzer(sentence))\n",
        "    \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "c_vec = CountVectorizer(analyzer=spanish_stemmer, stop_words=more_stop_words, lowercase=True)\n",
        "# tf_idf = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "c_vec_mat = c_vec.fit_transform(df_cleaned_sentences_list)\n",
        "# tf_idf_mat = tf_idf.fit_transform(c_vec_mat)\n",
        "c_vec_mat.shape"
      ],
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGnFBGAhzHRi",
        "outputId": "7ad4d693-800d-4394-aa87-c213e3bad4c6"
      },
      "source": [
        "df_c_vec = pd.DataFrame(c_vec_mat.toarray(), columns=c_vec.get_feature_names())\n",
        "print(df_c_vec)"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   aburr  abus  acost  agu  alcohol  alto  ...  usar  vam  vasit  vend  vid  viej\n",
            "0      0     0      0    0        0     1  ...     0    0      0     0    0     0\n",
            "1      0     0      0    0        0     0  ...     0    1      0     0    0     0\n",
            "2      0     0      0    3        0     0  ...     0    0      0     0    1     0\n",
            "3      0     0      0    0        0     0  ...     0    0      0     0    0     0\n",
            "4      0     0      1    0        0     0  ...     0    0      0     0    0     0\n",
            "5      0     0      0    0        1     0  ...     0    0      0     0    1     0\n",
            "6      0     1      0    0        0     0  ...     0    0      1     1    0     1\n",
            "7      1     0      0    0        0     0  ...     0    0      0     0    0     0\n",
            "8      0     0      0    0        0     0  ...     1    0      0     0    0     0\n",
            "9      0     0      0    0        0     0  ...     0    0      0     0    0     0\n",
            "\n",
            "[10 rows x 73 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CutgimzyLS"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Traducci√≥n Corpus\n",
        "\n",
        "# Descripci√≥n:\n",
        "\n",
        "Frente a la adversidad que supone que la gran mayor√≠a de modelos desarrollados en HuggingFace se encuentran en Ingl√©s, se ha optado por traducir el corpus al ingl√©s con el pipeline correspondiente. As√≠, podemos aprovecharlos para hacer Transfer Learning.\n",
        "\n",
        "Puesto que la fama de los transformers les antecede, consideramos que el error de los mismos de cara a las traducciones resulta asumible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p54MeEel0qxg"
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install sentencepiece"
      ],
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyzSC6zF1hoB"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "import tqdm"
      ],
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRTYsdk81lK-"
      },
      "source": [
        "# Autotokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")\n",
        "\n",
        "# Elecci√≥n/Descarga del modelo Preentrenado\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7uqO8oyD2mOg",
        "outputId": "7486855c-c466-4ebc-a1a5-120b2c8cc2bf"
      },
      "source": [
        "text"
      ],
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>text_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqu√© me hago la cabeza deooos</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "      <td>No se porqu√© me hago la cabeza deos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0</td>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "      <td>0</td>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1</td>\n",
              "      <td>Me aburro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0</td>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                            text_v2\n",
              "0  Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...  ...  Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...\n",
              "1  ‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...  ...  ‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...\n",
              "2  - ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...  ...  - ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...\n",
              "3              No se porqu√© me hago la cabeza deooos  ...                No se porqu√© me hago la cabeza deos\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...  Quisiera saber que hago durante la siesta de l...\n",
              "5  La persona que te dice que no se arrepiente de...  ...  La persona que te dice que no se arrepiente de...\n",
              "6  ‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...  ...  ‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...\n",
              "7                                       Meeee aburro  ...                                          Me aburro\n",
              "8  Macri le dijo las gordas que usar calzas est√° ...  ...  Macri le dijo las gordas que usar calzas est√° ...\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...                      JAVIER CHICALITO HERNANDEZ *7\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Zlw1G7Q9CzVv",
        "outputId": "ae893dce-b559-4afd-ad3d-139252514f2d"
      },
      "source": [
        "def get_corpus_translation(corpus):\n",
        "  from transformers import pipeline\n",
        "  pline = pipeline(\"translation_es_to_en\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "  def get_tweet_translation(tweet):\n",
        "    return pline(tweet.replace('.', '<point>'))[0]['translation_text']\n",
        "\n",
        "  return list(map(get_tweet_translation, corpus['text_v2'].to_list()))\n",
        "\n",
        "text['en_text'] = get_corpus_translation(text)\n",
        "\n",
        "text = text[['text', 'text_v2', 'en_text', 'len_token', 'n_char', 'ratio', 'detected_cansinos']]\n",
        "text"
      ],
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_v2</th>\n",
              "      <th>en_text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>Mental retardation levels: ‚Äî Low&lt;point&gt; ‚Äî Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>\"Come on, Luke, unscrew your saber, show your ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>- Do I offer you something?, Water, coffee, my...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqu√© me hago la cabeza deooos</td>\n",
              "      <td>No se porqu√© me hago la cabeza deos</td>\n",
              "      <td>I don't know why I'm doing my head.</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>I'd like to know what I do during the nap from...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>The person who tells you that he doesn't regre...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>\"Good Don Pepe, will you sell me a liter of mi...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>Me aburro</td>\n",
              "      <td>I'm bored.</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "      <td>Macri le dijo las gordas que usar calzas est√° ...</td>\n",
              "      <td>Macri told the fat ones that wearing socks is ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... detected_cansinos\n",
              "0  Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...  ...                 0\n",
              "1  ‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...  ...                 0\n",
              "2  - ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...  ...                 1\n",
              "3              No se porqu√© me hago la cabeza deooos  ...                 1\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...                 0\n",
              "5  La persona que te dice que no se arrepiente de...  ...                 0\n",
              "6  ‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...  ...                 0\n",
              "7                                       Meeee aburro  ...                 1\n",
              "8  Macri le dijo las gordas que usar calzas est√° ...  ...                 0\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...                 0\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbrUBiTrX93k"
      },
      "source": [
        "**I'm bored** antes se traduc√≠a como **meeee bored**, as√≠ que hemos ganado en calidad.\n",
        "\n",
        "Generar a partir de text_v2, text_v3 donde se pase text_v2 y se haga el spell_checker\n",
        "\n",
        "# Pendiente lo √∫ltimo: spell checker "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxLKPcNSYuGc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}