{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocesado_Inverso_Textos_SuperFinalV_git.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p54MeEel0qxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582fa755-5815-49a7-aaf7-946870c478df"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyzSC6zF1hoB"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA4UIVvs4DKk"
      },
      "source": [
        "# Carga Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSI_YWvt4BSx"
      },
      "source": [
        "train200k = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/train200k.csv\", sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DEAw16c4aZL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(train200k, test_size =0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m-Yrnh95PhS",
        "outputId": "b57e7b19-503d-4617-c378-4edd02a240fd"
      },
      "source": [
        "val['humor'].value_counts()\n",
        "\n",
        "# Me quedo con 1400 opiniones positivas\n",
        "np.random.seed(1)\n",
        "# get_n = 1400\n",
        "remove_n = 4000 # data.query('Sentiment == 2').shape[0] - get_n\n",
        "drop_indices = np.random.choice(val.query('humor == False').index, remove_n, replace=False)\n",
        "text = val.drop(drop_indices)\n",
        "\n",
        "text['humor'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     7965\n",
              "False    4035\n",
              "Name: humor, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "3Vwsit8U-9rP",
        "outputId": "4c14a4b9-c02e-4156-8dba-367ccfdce401"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151012</th>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77521</th>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90117</th>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135494</th>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17293</th>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5056</th>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150502</th>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53854</th>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22264</th>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104948</th>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows  2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  humor\n",
              "151012  Sheriff where sandra bland died says there's n...  False\n",
              "77521   Healthy indian takeout: 8 tips for making smar...  False\n",
              "90117   I really hope that death is a woman. that way ...   True\n",
              "135494  My therapist said that i second guess myself t...   True\n",
              "17293   What do you call a math teacher who's really i...   True\n",
              "...                                                   ...    ...\n",
              "5056    How come sneezes get a god bless you but cough...   True\n",
              "150502  Nick kristof: it's 'bogus' to say hillary is f...  False\n",
              "53854   In foreclosure-ridden florida, 'zombie' swimmi...  False\n",
              "22264        What do you call a man who can't stand? neal   True\n",
              "104948  Why weren't you at the halloween party? my cos...   True\n",
              "\n",
              "[12000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg40bU_6q_0a"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Word Emoji Context Matrix. ぃ   \n",
        "\n",
        "Descripci贸n: Extracci贸n/guardado de Emojis y depuraci贸n del Corpus\n",
        "\n",
        "Inconvenientes detectados con los emojis:\n",
        "\n",
        "* 1 Resulta que los emojis hemos podido verificar que countvectorizer los ignora. Es decir si las frases fueran solo emojis el shape de la matriz word context ser铆a (1,1), con valor empty.\n",
        "\n",
        "* 2 Aun suponiendo que exista alguna alternativa a countvectorizer muchas personas escriben palabras juntas con emojis, e.g.: 'man', lo que podr铆a generar un token m谩s del vocabulario que innecesario. Adem谩s pueden escribir varios emojis juntos , , , ... generando tambi茅n un problema en su identificaci贸n.\n",
        "\n",
        "La propuesta ha sido realizar un preproceso como el siguiente. Adem谩s, para solucionar el problema de los emoticonos, en lugar de pas谩rselos a countvectorizer en bruto utilizamos la decodificaci贸n a texto de la librer铆a emoji: **emoji.demojize()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIiT0DQFr7-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8efa954-2f90-4502-ffc9-413994c00f76"
      },
      "source": [
        "# %%capture\n",
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fZg102qqy3x"
      },
      "source": [
        "import emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtV7mIUrxI6"
      },
      "source": [
        "def extract_emojis(tweet):\n",
        "  return ''.join(c for c in tweet if c in emoji.UNICODE_EMOJI_ENGLISH)\n",
        "\n",
        "def get_emojilist(tweet):\n",
        "  emojistring = extract_emojis(tweet)\n",
        "  emojilist = [emoji for emoji in emojistring]\n",
        "  for emoji in emojilist:\n",
        "    tweet = tweet.replace(emoji, \"\")\n",
        "  return tweet, emojilist\n",
        "\n",
        "def get_emoji_sentence(tweet):\n",
        "  tweet, emojilist = get_emojilist(tweet)\n",
        "  emoji_sentence = emoji.demojize(' '.join(emojilist))\n",
        "  return tweet, emoji_sentence\n",
        "\n",
        "def filter(text_df):\n",
        "  filtered_df = pd.DataFrame(map(get_emoji_sentence, text_df['text'].to_list()))\n",
        "  filtered_df.rename(columns={0: 'sentences_without_emojis', 1: 'emoji_sentences'}, inplace=True)\n",
        "  return filtered_df\n",
        "\n",
        "df_filter_output = filter(text)\n",
        "\n",
        "df_cleaned_sentences = df_filter_output[['sentences_without_emojis']]\n",
        "# df_cleaned_sentences = df_filter_output['emoji_sentences']\n",
        "\n",
        "text['text_v1'] = df_filter_output['sentences_without_emojis'].to_list()\n",
        "\n",
        "emoji_sentences = df_filter_output['emoji_sentences']\n",
        "\n",
        "text['text_emojis'] = emoji_sentences.to_list()\n",
        "\n",
        "\n",
        "def get_emoji_vocab(emoji_sentence):\n",
        "  analyzer = CountVectorizer(binary=False, analyzer='word', # stop_words=more_stop_words,\n",
        "                              ngram_range=(1, 1)).build_analyzer()\n",
        "  return (emoji for emoji in analyzer(emoji_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHBFHP-dsILP"
      },
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer\n",
        "cv_emoji = CountVectorizer(analyzer=get_emoji_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXpdsPjBsOR0"
      },
      "source": [
        "try:\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "# Just if there is no emoji\n",
        "except ValueError:\n",
        "  emoji_sentences.loc[0,0] = emoji.demojize(\"\")\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "  \"\"\"emoji_sentences_test = emoji_sentences\"\"\"\n",
        "  \"\"\"emoji_sentences_test.loc[0,0] = \"\"\"\"\n",
        "  \"\"\"text['text_emojis'] = emoji_sentences_test.to_list()\"\"\"\n",
        "# cv_emoji.get_feature_names()\n",
        "\n",
        "\n",
        "text.replace({'text_emojis': {'': 'no_emojis'}}, inplace= True)\n",
        "\n",
        "corpus = text.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGX1lnvAZLzh",
        "outputId": "82f3179e-3b45-44c4-ebd7-16e7c138f523"
      },
      "source": [
        "cv_emoji.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos_button']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "C_DfuZRWUbyY",
        "outputId": "42be935b-64f1-423e-9748-3bb2893d5abb"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>text_v1</th>\n",
              "      <th>text_emojis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151012</th>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>False</td>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77521</th>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>False</td>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90117</th>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>True</td>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135494</th>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>True</td>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17293</th>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5056</th>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>True</td>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150502</th>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>False</td>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53854</th>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>False</td>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22264</th>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104948</th>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>True</td>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows  4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...  text_emojis\n",
              "151012  Sheriff where sandra bland died says there's n...  ...    no_emojis\n",
              "77521   Healthy indian takeout: 8 tips for making smar...  ...    no_emojis\n",
              "90117   I really hope that death is a woman. that way ...  ...    no_emojis\n",
              "135494  My therapist said that i second guess myself t...  ...    no_emojis\n",
              "17293   What do you call a math teacher who's really i...  ...    no_emojis\n",
              "...                                                   ...  ...          ...\n",
              "5056    How come sneezes get a god bless you but cough...  ...    no_emojis\n",
              "150502  Nick kristof: it's 'bogus' to say hillary is f...  ...    no_emojis\n",
              "53854   In foreclosure-ridden florida, 'zombie' swimmi...  ...    no_emojis\n",
              "22264        What do you call a man who can't stand? neal  ...    no_emojis\n",
              "104948  Why weren't you at the halloween party? my cos...  ...    no_emojis\n",
              "\n",
              "[12000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNvKkoiBPAN"
      },
      "source": [
        "# Detector de cansinos y correcci贸n de repeticiones innecesarias\n",
        "\n",
        "En twitter hay mucho \"pesao\" con el pulgar \"cansao\" y lo dejan mucho tiempo en el m贸ooooooooovil pulsando una letraaaaa. A todos estos, los consideramos unos pesaos y lo vamos a tener en cuenta. No quieren trabajar.\n",
        "\n",
        "驴Por qu茅 corregiremos tambi茅n a los pesaos? Porque spellchecker no puede, es f谩cil ver esto con un ejemplo en c贸digo. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDfM0P-AYdTm"
      },
      "source": [
        "def is_cansino(tweet, tolerancia:int=2):\n",
        "  # Consideramos pesados a todos aquellos\n",
        "  # que repitan 3 veces una letra\n",
        "  \"\"\"\n",
        "  Esta funci贸n identifica a los pesaos\n",
        "  Args:\n",
        "    tolerancia (int): tolerancia al pesao\n",
        "  \"\"\"\n",
        "  l1 = \"\"\n",
        "  rep = 0\n",
        "  letra = \"\"\n",
        "  tweet_aux = tweet + '<eos>'\n",
        "  for index, letra in enumerate(tweet_aux):\n",
        "      if letra == l1:\n",
        "          rep += 1\n",
        "      elif rep >= tolerancia:\n",
        "          return l1, rep, tolerancia, 1*True\n",
        "      else:\n",
        "        rep = 0\n",
        "        l1 = letra\n",
        "  return letra, 0, tolerancia, 1*False\n",
        "\n",
        "def get_cansinos(corpus):\n",
        "  L = list(map(is_cansino, corpus))\n",
        "  return [ret[3] for ret in L]\n",
        "\n",
        "###################################\n",
        "##### Correccion repeticiones #####\n",
        "###################################\n",
        "\n",
        "# Esto es beta solo corrige la primera\n",
        "# tanda de repeticiones se puede mejorar\n",
        "\n",
        "def tweet_corrector(tweet):\n",
        "    letra, rep, tolerancia, bool_ = is_cansino(tweet)\n",
        "    if bool_ == 1:\n",
        "        tweet = tweet.replace(rep*letra, '')\n",
        "        tweet = tweet_corrector(tweet)\n",
        "    return tweet\n",
        "\n",
        "def corpus_corrector(corpus):\n",
        "    L = list(map(tweet_corrector, corpus))\n",
        "    return L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KafDiR18bkO5",
        "outputId": "eb7bdf42-75d3-45cc-f7e6-c1c1da8a4de1"
      },
      "source": [
        "\"\"\"\n",
        "text.loc[7,'text_v2'] = 'Meeee aaaaabuuuuurroooooo'\n",
        "text\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntext.loc[7,'text_v2'] = 'Meeee aaaaabuuuuurroooooo'\\ntext\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7I8k8XfG-7M3",
        "outputId": "6541679d-5c03-4185-d2d0-7631fd9dd641"
      },
      "source": [
        "text['detected_text_cansinos'] = get_cansinos(text['text_v1'].to_list())\n",
        "text['detected_emojis_cansinos'] = get_cansinos(text['text_emojis'].to_list())\n",
        "text['detected_cansinos'] = (text['detected_text_cansinos'] + text['detected_emojis_cansinos']) % 2\n",
        "# text['detected_emojis_cansinos] | text['detected_text_cansinos'] \n",
        "\n",
        "text['text_v2'] = corpus_corrector(text['text_v1'].to_list())\n",
        "\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>text_v1</th>\n",
              "      <th>text_emojis</th>\n",
              "      <th>detected_text_cansinos</th>\n",
              "      <th>detected_emojis_cansinos</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>text_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151012</th>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>False</td>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77521</th>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>False</td>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90117</th>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>True</td>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135494</th>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>True</td>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17293</th>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5056</th>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>True</td>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150502</th>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>False</td>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53854</th>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>False</td>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22264</th>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104948</th>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>True</td>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows  8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...                                            text_v2\n",
              "151012  Sheriff where sandra bland died says there's n...  ...  Sheriff where sandra bland died says there's n...\n",
              "77521   Healthy indian takeout: 8 tips for making smar...  ...  Healthy indian takeout: 8 tips for making smar...\n",
              "90117   I really hope that death is a woman. that way ...  ...  I really hope that death is a woman. that way ...\n",
              "135494  My therapist said that i second guess myself t...  ...  My therapist said that i second guess myself t...\n",
              "17293   What do you call a math teacher who's really i...  ...  What do you call a math teacher who's really i...\n",
              "...                                                   ...  ...                                                ...\n",
              "5056    How come sneezes get a god bless you but cough...  ...  How come sneezes get a god bless you but cough...\n",
              "150502  Nick kristof: it's 'bogus' to say hillary is f...  ...  Nick kristof: it's 'bogus' to say hillary is f...\n",
              "53854   In foreclosure-ridden florida, 'zombie' swimmi...  ...  In foreclosure-ridden florida, 'zombie' swimmi...\n",
              "22264        What do you call a man who can't stand? neal  ...       What do you call a man who can't stand? neal\n",
              "104948  Why weren't you at the halloween party? my cos...  ...  Why weren't you at the halloween party? my cos...\n",
              "\n",
              "[12000 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CutgimzyLS"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Traducci贸n Corpus\n",
        "\n",
        "# Descripci贸n:\n",
        "\n",
        "Frente a la adversidad que supone que la gran mayor铆a de modelos desarrollados en HuggingFace se encuentran en Ingl茅s, se ha optado por traducir el corpus al ingl茅s con el pipeline correspondiente. As铆, podemos aprovecharlos para hacer Transfer Learning.\n",
        "\n",
        "Puesto que la fama de los transformers les antecede, consideramos que el error de los mismos de cara a las traducciones resulta asumible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRTYsdk81lK-"
      },
      "source": [
        "# Autotokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
        "\n",
        "# Elecci贸n/Descarga del modelo Preentrenado\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlw1G7Q9CzVv"
      },
      "source": [
        "def get_corpus_translation(corpus):\n",
        "  from transformers import pipeline\n",
        "  pline = pipeline(\"translation_en_to_es\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "  def get_tweet_translation(tweet):\n",
        "\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    tweet = tweet.replace('.', ' <.> ')\n",
        "    tweet = tweet.replace('...', ' . ')\n",
        "    \n",
        "\n",
        "    return pline(tweet)[0]['translation_text'] # punto <point>\n",
        "\n",
        "  return list(map(get_tweet_translation, corpus['text_v2'].to_list()))\n",
        "\n",
        "text['es_text'] = get_corpus_translation(text)\n",
        "\n",
        "def recover_point(tweet):\n",
        "  return tweet.replace('<.>', ' . ')\n",
        "\n",
        "def recover_point_corpus(corpus):\n",
        "  return list(map(recover_point, corpus))\n",
        "\n",
        "text['es_text'] = recover_point_corpus(text['es_text'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NLitx-r2YLs"
      },
      "source": [
        "text.to_csv('AumentadoDatos_EN.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}