{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Preprocesado_Inverso_Textos_SuperFinalV_git.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "p54MeEel0qxg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "582fa755-5815-49a7-aaf7-946870c478df"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install sentencepiece"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.7/dist-packages (4.6.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: huggingface-hub==0.0.8 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers) (20.9)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers) (4.0.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers) (0.0.45)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers) (0.10.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyzSC6zF1hoB"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CA4UIVvs4DKk"
      },
      "source": [
        "# Carga Datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bSI_YWvt4BSx"
      },
      "source": [
        "train200k = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/train200k.csv\", sep=',')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DEAw16c4aZL"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train, val = train_test_split(train200k, test_size =0.1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9m-Yrnh95PhS",
        "outputId": "b57e7b19-503d-4617-c378-4edd02a240fd"
      },
      "source": [
        "val['humor'].value_counts()\n",
        "\n",
        "# Me quedo con 1400 opiniones positivas\n",
        "np.random.seed(1)\n",
        "# get_n = 1400\n",
        "remove_n = 4000 # data.query('Sentiment == 2').shape[0] - get_n\n",
        "drop_indices = np.random.choice(val.query('humor == False').index, remove_n, replace=False)\n",
        "text = val.drop(drop_indices)\n",
        "\n",
        "text['humor'].value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True     7965\n",
              "False    4035\n",
              "Name: humor, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "3Vwsit8U-9rP",
        "outputId": "4c14a4b9-c02e-4156-8dba-367ccfdce401"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151012</th>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77521</th>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90117</th>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135494</th>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17293</th>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5056</th>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150502</th>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53854</th>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>False</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22264</th>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104948</th>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>True</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  humor\n",
              "151012  Sheriff where sandra bland died says there's n...  False\n",
              "77521   Healthy indian takeout: 8 tips for making smar...  False\n",
              "90117   I really hope that death is a woman. that way ...   True\n",
              "135494  My therapist said that i second guess myself t...   True\n",
              "17293   What do you call a math teacher who's really i...   True\n",
              "...                                                   ...    ...\n",
              "5056    How come sneezes get a god bless you but cough...   True\n",
              "150502  Nick kristof: it's 'bogus' to say hillary is f...  False\n",
              "53854   In foreclosure-ridden florida, 'zombie' swimmi...  False\n",
              "22264        What do you call a man who can't stand? neal   True\n",
              "104948  Why weren't you at the halloween party? my cos...   True\n",
              "\n",
              "[12000 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg40bU_6q_0a"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Word Emoji Context Matrix. 🤣 😆 😂 \n",
        "\n",
        "Descripción: Extracción/guardado de Emojis y depuración del Corpus\n",
        "\n",
        "Inconvenientes detectados con los emojis:\n",
        "\n",
        "* 1 Resulta que los emojis hemos podido verificar que countvectorizer los ignora. Es decir si las frases fueran solo emojis el shape de la matriz word context sería (1,1), con valor empty.\n",
        "\n",
        "* 2 Aun suponiendo que exista alguna alternativa a countvectorizer muchas personas escriben palabras juntas con emojis, e.g.: 'man👨', lo que podría generar un token más del vocabulario que innecesario. Además pueden escribir varios emojis juntos 👨, 👨👨, 👨👨👨, ... generando también un problema en su identificación.\n",
        "\n",
        "La propuesta ha sido realizar un preproceso como el siguiente. Además, para solucionar el problema de los emoticonos, en lugar de pasárselos a countvectorizer en bruto utilizamos la decodificación a texto de la librería emoji: **emoji.demojize()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIiT0DQFr7-D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b8efa954-2f90-4502-ffc9-413994c00f76"
      },
      "source": [
        "# %%capture\n",
        "!pip install emoji"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: emoji in /usr/local/lib/python3.7/dist-packages (1.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fZg102qqy3x"
      },
      "source": [
        "import emoji"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtV7mIUrxI6"
      },
      "source": [
        "def extract_emojis(tweet):\n",
        "  return ''.join(c for c in tweet if c in emoji.UNICODE_EMOJI_ENGLISH)\n",
        "\n",
        "def get_emojilist(tweet):\n",
        "  emojistring = extract_emojis(tweet)\n",
        "  emojilist = [emoji for emoji in emojistring]\n",
        "  for emoji in emojilist:\n",
        "    tweet = tweet.replace(emoji, \"\")\n",
        "  return tweet, emojilist\n",
        "\n",
        "def get_emoji_sentence(tweet):\n",
        "  tweet, emojilist = get_emojilist(tweet)\n",
        "  emoji_sentence = emoji.demojize(' '.join(emojilist))\n",
        "  return tweet, emoji_sentence\n",
        "\n",
        "def filter(text_df):\n",
        "  filtered_df = pd.DataFrame(map(get_emoji_sentence, text_df['text'].to_list()))\n",
        "  filtered_df.rename(columns={0: 'sentences_without_emojis', 1: 'emoji_sentences'}, inplace=True)\n",
        "  return filtered_df\n",
        "\n",
        "df_filter_output = filter(text)\n",
        "\n",
        "df_cleaned_sentences = df_filter_output[['sentences_without_emojis']]\n",
        "# df_cleaned_sentences = df_filter_output['emoji_sentences']\n",
        "\n",
        "text['text_v1'] = df_filter_output['sentences_without_emojis'].to_list()\n",
        "\n",
        "emoji_sentences = df_filter_output['emoji_sentences']\n",
        "\n",
        "text['text_emojis'] = emoji_sentences.to_list()\n",
        "\n",
        "\n",
        "def get_emoji_vocab(emoji_sentence):\n",
        "  analyzer = CountVectorizer(binary=False, analyzer='word', # stop_words=more_stop_words,\n",
        "                              ngram_range=(1, 1)).build_analyzer()\n",
        "  return (emoji for emoji in analyzer(emoji_sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHBFHP-dsILP"
      },
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer\n",
        "cv_emoji = CountVectorizer(analyzer=get_emoji_vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXpdsPjBsOR0"
      },
      "source": [
        "try:\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "# Just if there is no emoji\n",
        "except ValueError:\n",
        "  emoji_sentences.loc[0,0] = emoji.demojize(\"🆘\")\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "  \"\"\"emoji_sentences_test = emoji_sentences\"\"\"\n",
        "  \"\"\"emoji_sentences_test.loc[0,0] = \"🆘🆘🆘🆘🆘🆘🆘🆘\"\"\"\n",
        "  \"\"\"text['text_emojis'] = emoji_sentences_test.to_list()\"\"\"\n",
        "# cv_emoji.get_feature_names()\n",
        "\n",
        "\n",
        "text.replace({'text_emojis': {'': 'no_emojis'}}, inplace= True)\n",
        "\n",
        "corpus = text.copy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGX1lnvAZLzh",
        "outputId": "82f3179e-3b45-44c4-ebd7-16e7c138f523"
      },
      "source": [
        "cv_emoji.get_feature_names()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos_button']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 402
        },
        "id": "C_DfuZRWUbyY",
        "outputId": "42be935b-64f1-423e-9748-3bb2893d5abb"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>text_v1</th>\n",
              "      <th>text_emojis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151012</th>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>False</td>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77521</th>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>False</td>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90117</th>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>True</td>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135494</th>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>True</td>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17293</th>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5056</th>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>True</td>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150502</th>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>False</td>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53854</th>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>False</td>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22264</th>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104948</th>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>True</td>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>no_emojis</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...  text_emojis\n",
              "151012  Sheriff where sandra bland died says there's n...  ...    no_emojis\n",
              "77521   Healthy indian takeout: 8 tips for making smar...  ...    no_emojis\n",
              "90117   I really hope that death is a woman. that way ...  ...    no_emojis\n",
              "135494  My therapist said that i second guess myself t...  ...    no_emojis\n",
              "17293   What do you call a math teacher who's really i...  ...    no_emojis\n",
              "...                                                   ...  ...          ...\n",
              "5056    How come sneezes get a god bless you but cough...  ...    no_emojis\n",
              "150502  Nick kristof: it's 'bogus' to say hillary is f...  ...    no_emojis\n",
              "53854   In foreclosure-ridden florida, 'zombie' swimmi...  ...    no_emojis\n",
              "22264        What do you call a man who can't stand? neal  ...    no_emojis\n",
              "104948  Why weren't you at the halloween party? my cos...  ...    no_emojis\n",
              "\n",
              "[12000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNvKkoiBPAN"
      },
      "source": [
        "# Detector de cansinos y corrección de repeticiones innecesarias\n",
        "\n",
        "En twitter hay mucho \"pesao\" con el pulgar \"cansao\" y lo dejan mucho tiempo en el móooooooooovil pulsando una letraaaaa. A todos estos, los consideramos unos pesaos y lo vamos a tener en cuenta. No quieren trabajar.\n",
        "\n",
        "¿Por qué corregiremos también a los pesaos? Porque spellchecker no puede, es fácil ver esto con un ejemplo en código. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pDfM0P-AYdTm"
      },
      "source": [
        "def is_cansino(tweet, tolerancia:int=2):\n",
        "  # Consideramos pesados a todos aquellos\n",
        "  # que repitan 3 veces una letra\n",
        "  \"\"\"\n",
        "  Esta función identifica a los pesaos\n",
        "  Args:\n",
        "    tolerancia (int): tolerancia al pesao\n",
        "  \"\"\"\n",
        "  l1 = \"\"\n",
        "  rep = 0\n",
        "  letra = \"\"\n",
        "  tweet_aux = tweet + '<eos>'\n",
        "  for index, letra in enumerate(tweet_aux):\n",
        "      if letra == l1:\n",
        "          rep += 1\n",
        "      elif rep >= tolerancia:\n",
        "          return l1, rep, tolerancia, 1*True\n",
        "      else:\n",
        "        rep = 0\n",
        "        l1 = letra\n",
        "  return letra, 0, tolerancia, 1*False\n",
        "\n",
        "def get_cansinos(corpus):\n",
        "  L = list(map(is_cansino, corpus))\n",
        "  return [ret[3] for ret in L]\n",
        "\n",
        "###################################Ç\n",
        "##### Correccion repeticiones #####\n",
        "###################################\n",
        "\n",
        "# Esto es beta solo corrige la primera\n",
        "# tanda de repeticiones se puede mejorar\n",
        "\n",
        "def tweet_corrector(tweet):\n",
        "    letra, rep, tolerancia, bool_ = is_cansino(tweet)\n",
        "    if bool_ == 1:\n",
        "        tweet = tweet.replace(rep*letra, '')\n",
        "        tweet = tweet_corrector(tweet)\n",
        "    return tweet\n",
        "\n",
        "def corpus_corrector(corpus):\n",
        "    L = list(map(tweet_corrector, corpus))\n",
        "    return L"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KafDiR18bkO5",
        "outputId": "eb7bdf42-75d3-45cc-f7e6-c1c1da8a4de1"
      },
      "source": [
        "\"\"\"\n",
        "text.loc[7,'text_v2'] = 'Meeee aaaaabuuuuurroooooo'\n",
        "text\n",
        "\"\"\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\ntext.loc[7,'text_v2'] = 'Meeee aaaaabuuuuurroooooo'\\ntext\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7I8k8XfG-7M3",
        "outputId": "6541679d-5c03-4185-d2d0-7631fd9dd641"
      },
      "source": [
        "text['detected_text_cansinos'] = get_cansinos(text['text_v1'].to_list())\n",
        "text['detected_emojis_cansinos'] = get_cansinos(text['text_emojis'].to_list())\n",
        "text['detected_cansinos'] = (text['detected_text_cansinos'] + text['detected_emojis_cansinos']) % 2\n",
        "# text['detected_emojis_cansinos] | text['detected_text_cansinos'] \n",
        "\n",
        "text['text_v2'] = corpus_corrector(text['text_v1'].to_list())\n",
        "\n",
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>humor</th>\n",
              "      <th>text_v1</th>\n",
              "      <th>text_emojis</th>\n",
              "      <th>detected_text_cansinos</th>\n",
              "      <th>detected_emojis_cansinos</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>text_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>151012</th>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>False</td>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Sheriff where sandra bland died says there's n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77521</th>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>False</td>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Healthy indian takeout: 8 tips for making smar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90117</th>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>True</td>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>I really hope that death is a woman. that way ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135494</th>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>True</td>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>My therapist said that i second guess myself t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17293</th>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>What do you call a math teacher who's really i...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5056</th>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>True</td>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>How come sneezes get a god bless you but cough...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150502</th>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>False</td>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Nick kristof: it's 'bogus' to say hillary is f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53854</th>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>False</td>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>In foreclosure-ridden florida, 'zombie' swimmi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22264</th>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>True</td>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>What do you call a man who can't stand? neal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104948</th>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>True</td>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Why weren't you at the halloween party? my cos...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>12000 rows × 8 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                     text  ...                                            text_v2\n",
              "151012  Sheriff where sandra bland died says there's n...  ...  Sheriff where sandra bland died says there's n...\n",
              "77521   Healthy indian takeout: 8 tips for making smar...  ...  Healthy indian takeout: 8 tips for making smar...\n",
              "90117   I really hope that death is a woman. that way ...  ...  I really hope that death is a woman. that way ...\n",
              "135494  My therapist said that i second guess myself t...  ...  My therapist said that i second guess myself t...\n",
              "17293   What do you call a math teacher who's really i...  ...  What do you call a math teacher who's really i...\n",
              "...                                                   ...  ...                                                ...\n",
              "5056    How come sneezes get a god bless you but cough...  ...  How come sneezes get a god bless you but cough...\n",
              "150502  Nick kristof: it's 'bogus' to say hillary is f...  ...  Nick kristof: it's 'bogus' to say hillary is f...\n",
              "53854   In foreclosure-ridden florida, 'zombie' swimmi...  ...  In foreclosure-ridden florida, 'zombie' swimmi...\n",
              "22264        What do you call a man who can't stand? neal  ...       What do you call a man who can't stand? neal\n",
              "104948  Why weren't you at the halloween party? my cos...  ...  Why weren't you at the halloween party? my cos...\n",
              "\n",
              "[12000 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CutgimzyLS"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Traducción Corpus\n",
        "\n",
        "# Descripción:\n",
        "\n",
        "Frente a la adversidad que supone que la gran mayoría de modelos desarrollados en HuggingFace se encuentran en Inglés, se ha optado por traducir el corpus al inglés con el pipeline correspondiente. Así, podemos aprovecharlos para hacer Transfer Learning.\n",
        "\n",
        "Puesto que la fama de los transformers les antecede, consideramos que el error de los mismos de cara a las traducciones resulta asumible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRTYsdk81lK-"
      },
      "source": [
        "# Autotokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")\n",
        "\n",
        "# Elección/Descarga del modelo Preentrenado\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-en-es\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zlw1G7Q9CzVv"
      },
      "source": [
        "def get_corpus_translation(corpus):\n",
        "  from transformers import pipeline\n",
        "  pline = pipeline(\"translation_en_to_es\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "  def get_tweet_translation(tweet):\n",
        "\n",
        "    tweet = tweet.lower()\n",
        "\n",
        "    tweet = tweet.replace('.', ' <.> ')\n",
        "    tweet = tweet.replace('...', ' . ')\n",
        "    \n",
        "\n",
        "    return pline(tweet)[0]['translation_text'] # punto <point>\n",
        "\n",
        "  return list(map(get_tweet_translation, corpus['text_v2'].to_list()))\n",
        "\n",
        "text['es_text'] = get_corpus_translation(text)\n",
        "\n",
        "def recover_point(tweet):\n",
        "  return tweet.replace('<.>', ' . ')\n",
        "\n",
        "def recover_point_corpus(corpus):\n",
        "  return list(map(recover_point, corpus))\n",
        "\n",
        "text['es_text'] = recover_point_corpus(text['es_text'])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NLitx-r2YLs"
      },
      "source": [
        "text.to_csv('AumentadoDatos_EN.csv')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}