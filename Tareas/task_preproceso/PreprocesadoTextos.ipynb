{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PreprocesadoTextos.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Mj-ks6fqT25"
      },
      "source": [
        " # Todas las cuestiones relativas al preprocesado figuran en este Collab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mrsy19b21q6J"
      },
      "source": [
        "#### **Recordatorio**: aunque todo este preprocesado se haya hecho en grupo, se recuerda que la redacción ha de ser personalizada."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73QBKRpzqasp"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Length Features\n",
        "\n",
        "Aquí se recogen algunas variables relacionadas con la longitud de la frase tanto a nivel de token como a nivel de caracter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rPxleGp6p6BH"
      },
      "source": [
        "import pandas as pd\n",
        "train_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/haha_2021_train.csv\", sep=',')"
      ],
      "execution_count": 455,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0P3h2Zvqxqz"
      },
      "source": [
        "text = train_dataframe[['text']]\n",
        "text = text.iloc[0:10,:]"
      ],
      "execution_count": 456,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "_YWgPaW5qswt",
        "outputId": "8c2d661a-882a-4116-c796-99a8996173c5"
      },
      "source": [
        "def len_token(tweet):\n",
        "  tweet_tokens = tweet.replace('\\n', ' ').split(' ')\n",
        "  return len(tweet_tokens)\n",
        "def n_characters_tweet(tweet):\n",
        "  tweet = tweet.replace('\\n', ' ')\n",
        "  return len(tweet)\n",
        "\n",
        "def get_len_token(text):\n",
        "  return list(map(len_token, text['text'].to_list()))\n",
        "\n",
        "def get_n_characters_tweet(text):\n",
        "  return list(map(n_characters_tweet, text['text'].to_list()))\n",
        "\n",
        "def get_n_characters_tweet(text):\n",
        "  return list(map(n_characters_tweet, text['text'].to_list()))\n",
        "\n",
        "text['len_token'] = get_len_token(text)\n",
        "\n",
        "text['n_char'] = get_n_characters_tweet(text)\n",
        "\n",
        "text['ratio'] = text['len_token']/text['n_char']\n",
        "\n",
        "text"
      ],
      "execution_count": 457,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...     ratio\n",
              "0  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...  ...  0.220930\n",
              "1  —Vamos Luke desenfunda tu sable, demuestra tu ...  ...  0.157143\n",
              "2  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...  ...  0.187500\n",
              "3              No se porqué me hago la cabeza deooos  ...  0.216216\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...  0.188679\n",
              "5  La persona que te dice que no se arrepiente de...  ...  0.216667\n",
              "6  —Buenas don Pepe, ¿me vende un litro de leche?...  ...  0.169643\n",
              "7                                       Meeee aburro  ...  0.166667\n",
              "8  Macri le dijo las gordas que usar calzas está ...  ...  0.196078\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...  0.137931\n",
              "\n",
              "[10 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 457
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fvNuLb2w-5ZD"
      },
      "source": [
        "---\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSNvKkoiBPAN"
      },
      "source": [
        "# Detector de cansinos y corrección de repeticiones innecesarias\n",
        "\n",
        "En twitter hay mucho \"pesao\" con el pulgar \"cansao\" y lo dejan mucho tiempo en el móooooooooovil pulsando una letraaaaa. A todos estos, los consideramos unos pesaos y lo vamos a tener en cuenta. No quieren trabajar.\n",
        "\n",
        "¿Por qué corregiremos también a los pesaos? Porque spellchecker no puede, es fácil ver esto con un ejemplo en código. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7I8k8XfG-7M3",
        "outputId": "6db519d4-b9c5-4c0b-c541-769b045f69de"
      },
      "source": [
        "def is_cansino(tweet, tolerancia:int=2):\n",
        "  # Consideramos pesados a todos aquellos\n",
        "  # que repitan 3 veces una letra\n",
        "  \"\"\"\n",
        "  Esta función identifica a los pesaos\n",
        "  Args:\n",
        "    tolerancia (int): tolerancia al pesao\n",
        "  \"\"\"\n",
        "  l1 = \"\"\n",
        "  rep = 0\n",
        "  for index, letra in enumerate(tweet):\n",
        "      if letra == l1:\n",
        "          rep += 1\n",
        "      elif rep >= tolerancia:\n",
        "          return l1, rep, tolerancia, 1*True\n",
        "      else:\n",
        "        rep = 0\n",
        "        l1 = letra\n",
        "  return letra, 0, tolerancia, 1*False\n",
        "\n",
        "def get_cansinos(corpus):\n",
        "  L = list(map(is_cansino, corpus))\n",
        "  return [ret[3] for ret in L]\n",
        "\n",
        "###################################\n",
        "##### Correccion repeticiones #####\n",
        "###################################\n",
        "\n",
        "# Esto es beta solo corrige la primera\n",
        "# tanda de repeticiones se puede mejorar\n",
        "\n",
        "def tweet_corrector(tweet):\n",
        "    letra, rep, tolerancia, bool_ = is_cansino(tweet)\n",
        "    if bool_ == 1:\n",
        "        tweet = tweet.replace(rep*letra, '')\n",
        "    return tweet\n",
        "\n",
        "def corpus_corrector(corpus):\n",
        "    L = list(map(tweet_corrector, corpus))\n",
        "    return L\n",
        "\n",
        "text['detected_cansinos'] = get_cansinos(text['text'].to_list())\n",
        "\n",
        "text['text_v2'] = corpus_corrector(text['text'].to_list())\n",
        "\n",
        "text"
      ],
      "execution_count": 458,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>text_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "      <td>No se porqué me hago la cabeza deos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0</td>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "      <td>0</td>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1</td>\n",
              "      <td>Me aburro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0</td>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                            text_v2\n",
              "0  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...  ...  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...\n",
              "1  —Vamos Luke desenfunda tu sable, demuestra tu ...  ...  —Vamos Luke desenfunda tu sable, demuestra tu ...\n",
              "2  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...  ...  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...\n",
              "3              No se porqué me hago la cabeza deooos  ...                No se porqué me hago la cabeza deos\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...  Quisiera saber que hago durante la siesta de l...\n",
              "5  La persona que te dice que no se arrepiente de...  ...  La persona que te dice que no se arrepiente de...\n",
              "6  —Buenas don Pepe, ¿me vende un litro de leche?...  ...  —Buenas don Pepe, ¿me vende un litro de leche?...\n",
              "7                                       Meeee aburro  ...                                          Me aburro\n",
              "8  Macri le dijo las gordas que usar calzas está ...  ...  Macri le dijo las gordas que usar calzas está ...\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...                      JAVIER CHICALITO HERNANDEZ *7\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 458
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GPp8qqtHNHRV"
      },
      "source": [
        ""
      ],
      "execution_count": 458,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "RnLPsA9_WmOb",
        "outputId": "69877865-05f3-4e99-f679-5dc340655c46"
      },
      "source": [
        "count = 3\n",
        "string = 'holaaaa'\n",
        "string.replace(count*'a', '')"
      ],
      "execution_count": 459,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hola'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 459
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L8km82u1ang5"
      },
      "source": [
        "## **warning** ME he dado cuenta de esto antes de irme a dormir CUIDADOOOOOOOOOO perdemos la frecuencia de los emojisssssssssssssss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "HYbqUM8AaegB",
        "outputId": "b01c2a4d-53c1-4e09-cb1d-9ae51486f7e4"
      },
      "source": [
        "string = \"😂😂😂😂\"\n",
        "string.replace(\"😂\"*3, '')"
      ],
      "execution_count": 481,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'😂'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 481
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J5mKE0s-Iwyi"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# SpellChecker (Corrector ortográfico)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y4NFs9wbJUOh"
      },
      "source": [
        "# SpellChecker creo que no hace falta, pero por si acaso la dejo\n",
        "# !pip install SpellChecker"
      ],
      "execution_count": 460,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqRUmrkeJS24"
      },
      "source": [
        "# pyspellchecker si hace falta instalarla\n",
        "# !pip install pyspellchecker\n",
        "from spellchecker import SpellChecker"
      ],
      "execution_count": 461,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CZcxEdQYJADg",
        "outputId": "3626d5e8-3729-4411-8c32-c46053234417"
      },
      "source": [
        "spell_check  = SpellChecker(language='es', distance=100)\n",
        "spell_check.correction(\"chicxs\")"
      ],
      "execution_count": 462,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'chicos'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 462
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vg40bU_6q_0a"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Word Emoji Context Matrix. 🤣 😆 😂 \n",
        "\n",
        "Descripción: Extracción/guardado de Emojis y depuración del Corpus\n",
        "\n",
        "Inconvenientes detectados con los emojis:\n",
        "\n",
        "* 1 Resulta que los emojis hemos podido verificar que countvectorizer los ignora. Es decir si las frases fueran solo emojis el shape de la matriz word context sería (1,1), con valor empty.\n",
        "\n",
        "* 2 Aun suponiendo que exista alguna alternativa a countvectorizer muchas personas escriben palabras juntas con emojis, e.g.: 'man👨', lo que podría generar un token más del vocabulario que innecesario. Además pueden escribir varios emojis juntos 👨, 👨👨, 👨👨👨, ... generando también un problema en su identificación.\n",
        "\n",
        "La propuesta ha sido realizar un preproceso como el siguiente. Además, para solucionar el problema de los emoticonos, en lugar de pasárselos a countvectorizer en bruto utilizamos la decodificación a texto de la librería emoji: **emoji.demojize()**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pIiT0DQFr7-D"
      },
      "source": [
        "# %%capture\n",
        "# !pip install emoji"
      ],
      "execution_count": 463,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fZg102qqy3x"
      },
      "source": [
        "import emoji"
      ],
      "execution_count": 464,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrtV7mIUrxI6"
      },
      "source": [
        "def extract_emojis(tweet):\n",
        "  return ''.join(c for c in tweet if c in emoji.UNICODE_EMOJI_ENGLISH)\n",
        "\n",
        "def get_emojilist(tweet):\n",
        "  emojistring = extract_emojis(tweet)\n",
        "  emojilist = [emoji for emoji in emojistring]\n",
        "  for emoji in emojilist:\n",
        "    tweet = tweet.replace(emoji, \"\")\n",
        "  return tweet, emojilist\n",
        "\n",
        "def get_emoji_sentence(tweet):\n",
        "  tweet, emojilist = get_emojilist(tweet)\n",
        "  emoji_sentence = emoji.demojize(' '.join(emojilist))\n",
        "  return tweet, emoji_sentence\n",
        "\n",
        "def filter(text_df):\n",
        "  filtered_df = pd.DataFrame(map(get_emoji_sentence, text_df['text_v2'].to_list()))\n",
        "  filtered_df.rename(columns={0: 'sentences_without_emojis', 1: 'emoji_sentences'}, inplace=True)\n",
        "  return filtered_df\n",
        "\n",
        "df_filter_output = filter(text)\n",
        "\n",
        "df_cleaned_sentences = df_filter_output[['sentences_without_emojis']]\n",
        "emoji_sentences = df_filter_output['emoji_sentences']\n",
        "\n",
        "def get_emoji_vocab(emoji_sentence):\n",
        "  analyzer = CountVectorizer(binary=False, analyzer='word', # stop_words=more_stop_words,\n",
        "                              ngram_range=(1, 1)).build_analyzer()\n",
        "  return (emoji for emoji in analyzer(emoji_sentence))"
      ],
      "execution_count": 465,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RHBFHP-dsILP"
      },
      "source": [
        "from sklearn.feature_extraction.text import  CountVectorizer\n",
        "cv_emoji = CountVectorizer(analyzer=get_emoji_vocab)"
      ],
      "execution_count": 466,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QXpdsPjBsOR0"
      },
      "source": [
        "try:\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "# Just if there is no emoji\n",
        "except ValueError:\n",
        "  emoji_sentences.loc[0,0] = emoji.demojize(\"🆘\")\n",
        "  word_context_emoji = cv_emoji.fit_transform(emoji_sentences.to_list())\n",
        "# cv_emoji.get_feature_names()"
      ],
      "execution_count": 467,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kGX1lnvAZLzh",
        "outputId": "40e0cba0-a9fb-4b86-f116-83469b185310"
      },
      "source": [
        "cv_emoji.get_feature_names()"
      ],
      "execution_count": 480,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sos_button']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 480
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mAHq7-UxsXQk"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Obtención de Stop Words"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_wIzMFmFsSL0"
      },
      "source": [
        "# %%capture\n",
        "# !pip install stop_words"
      ],
      "execution_count": 468,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JkMEdYs0scJi",
        "outputId": "987668f4-0832-413a-f3a0-880a2f836ba8"
      },
      "source": [
        "from stop_words import get_stop_words # Se añade librería para obtener las stop_word de cualquier idioma\n",
        "!wget \"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\"\n",
        "\n",
        "# Se obtienen las stop_words en español\n",
        "import pickle\n",
        "with open(\"more_stop_words.txt\", \"rb\") as f:\n",
        "  list_test = pickle.load(f)\n",
        "\n",
        "stop_words = get_stop_words(\"spanish\")\n",
        "more_stop_words = stop_words + list_test\n",
        "more_stop_words.sort()"
      ],
      "execution_count": 469,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 23:59:36--  https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10258 (10K) [application/octet-stream]\n",
            "Saving to: ‘more_stop_words.txt.8’\n",
            "\n",
            "\rmore_stop_words.txt   0%[                    ]       0  --.-KB/s               \rmore_stop_words.txt 100%[===================>]  10.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-21 23:59:36 (62.6 MB/s) - ‘more_stop_words.txt.8’ saved [10258/10258]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "plCYOpqytS6q"
      },
      "source": [
        "# ELIMINACIÓN DE IDIOMAS ALEJADOS DEL ESPAÑOL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwRexGeKt7Zo"
      },
      "source": [
        "# !pip install spacy_langdetect"
      ],
      "execution_count": 470,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5hlWpW9kyD8n"
      },
      "source": [
        "# frase de prueba\n",
        "# text = '¿Hola cómo سمبأسكمق estáis? 종현아생일축하해'"
      ],
      "execution_count": 471,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gsY5GPpMta-e",
        "outputId": "b95797f3-d6cb-46cf-e0a3-332fed38a996"
      },
      "source": [
        "import spacy\n",
        "from spacy_langdetect import LanguageDetector\n",
        "\n",
        "# sentence level language detection\n",
        "dict_ = {}\n",
        "\n",
        "nlp = spacy.load('en')\n",
        "nlp.add_pipe(LanguageDetector(), name='language_detector', last=True)\n",
        "\n",
        "# Eliminamos palabras koreanas, vietnamitas, japonesas o árabes\n",
        "L = ['ko', 'vi', 'ja', 'ar']\n",
        "df_cleaned_sentences_list = df_cleaned_sentences['sentences_without_emojis'].to_list()\n",
        "for index, sentence in enumerate(df_cleaned_sentences_list):\n",
        "  doc = nlp(sentence)\n",
        "  for subsent in doc.sents:\n",
        "    if subsent._.language['language'] in L:\n",
        "      df_cleaned_sentences_list[index] = sentence.replace(subsent.text,'')\n",
        "df_cleaned_sentences_list"
      ],
      "execution_count": 472,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Niveles de retraso mental: \\n\\n— Bajo.\\n— Medio.\\n— Alto.\\n— Elevado.\\n— Regresar con tu ex.',\n",
              " '—Vamos Luke desenfunda tu sable, demuestra tu odio, que perteneces al lado oscuro\\n—Señor súbase los pantalones o llamo a seguridad.\\n—JAJAJA.',\n",
              " '- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, mi vida entera?\\n-Agua está bien\\n-Pero yo creí que.\\n- ¡AGUA DIJE!',\n",
              " 'No se porqué me hago la cabeza deos',\n",
              " 'Quisiera saber que hago durante la siesta de la cual me levanto más cansado que cuando me acosté a dormir.',\n",
              " 'La persona que te dice que no se arrepiente de nada en la vida, o no toma alcohol, o no lleva el celular cuando lo hace.',\n",
              " '—Buenas don Pepe, ¿me vende un litro de leche?\\n—¿Entera?\\n—No, si quiere tómese un vasito pinche viejo abusivo...',\n",
              " 'Me aburro',\n",
              " 'Macri le dijo las gordas que usar calzas está bien.',\n",
              " 'JAVIER CHICALITO HERNANDEZ *7']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 472
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Db8Z3XeEyfj1"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# CREACION MATRIZ WORD CONTEXT DEL TEXTO DEPURADO (SIN EMOJIS y sin idiomas poco habituales)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3HmJbsGtz7a",
        "outputId": "162e4312-b31e-4e09-87a7-28f675685a5e"
      },
      "source": [
        "from nltk.stem.snowball import SpanishStemmer\n",
        "def spanish_stemmer(sentence):\n",
        "    stemmer = SpanishStemmer()\n",
        "    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=more_stop_words,\n",
        "                               ngram_range=(1, 1)).build_analyzer()\n",
        "    return (stemmer.stem(word) for word in analyzer(sentence))\n",
        "    \n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "c_vec = CountVectorizer(analyzer=spanish_stemmer, stop_words=more_stop_words, lowercase=True)\n",
        "# tf_idf = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "c_vec_mat = c_vec.fit_transform(df_cleaned_sentences_list)\n",
        "# tf_idf_mat = tf_idf.fit_transform(c_vec_mat)\n",
        "c_vec_mat.shape"
      ],
      "execution_count": 473,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 73)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 473
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MGnFBGAhzHRi",
        "outputId": "7ad4d693-800d-4394-aa87-c213e3bad4c6"
      },
      "source": [
        "df_c_vec = pd.DataFrame(c_vec_mat.toarray(), columns=c_vec.get_feature_names())\n",
        "print(df_c_vec)"
      ],
      "execution_count": 474,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   aburr  abus  acost  agu  alcohol  alto  ...  usar  vam  vasit  vend  vid  viej\n",
            "0      0     0      0    0        0     1  ...     0    0      0     0    0     0\n",
            "1      0     0      0    0        0     0  ...     0    1      0     0    0     0\n",
            "2      0     0      0    3        0     0  ...     0    0      0     0    1     0\n",
            "3      0     0      0    0        0     0  ...     0    0      0     0    0     0\n",
            "4      0     0      1    0        0     0  ...     0    0      0     0    0     0\n",
            "5      0     0      0    0        1     0  ...     0    0      0     0    1     0\n",
            "6      0     1      0    0        0     0  ...     0    0      1     1    0     1\n",
            "7      1     0      0    0        0     0  ...     0    0      0     0    0     0\n",
            "8      0     0      0    0        0     0  ...     1    0      0     0    0     0\n",
            "9      0     0      0    0        0     0  ...     0    0      0     0    0     0\n",
            "\n",
            "[10 rows x 73 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x5CutgimzyLS"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Traducción Corpus\n",
        "\n",
        "# Descripción:\n",
        "\n",
        "Frente a la adversidad que supone que la gran mayoría de modelos desarrollados en HuggingFace se encuentran en Inglés, se ha optado por traducir el corpus al inglés con el pipeline correspondiente. Así, podemos aprovecharlos para hacer Transfer Learning.\n",
        "\n",
        "Puesto que la fama de los transformers les antecede, consideramos que el error de los mismos de cara a las traducciones resulta asumible."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p54MeEel0qxg"
      },
      "source": [
        "# !pip install transformers\n",
        "# !pip install sentencepiece"
      ],
      "execution_count": 475,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PyzSC6zF1hoB"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "from transformers import AutoModelForSequenceClassification, pipeline\n",
        "import tqdm"
      ],
      "execution_count": 476,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hRTYsdk81lK-"
      },
      "source": [
        "# Autotokenizador\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")\n",
        "\n",
        "# Elección/Descarga del modelo Preentrenado\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"Helsinki-NLP/opus-mt-es-en\")"
      ],
      "execution_count": 477,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "7uqO8oyD2mOg",
        "outputId": "7486855c-c466-4ebc-a1a5-120b2c8cc2bf"
      },
      "source": [
        "text"
      ],
      "execution_count": 478,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>text_v2</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "      <td>No se porqué me hago la cabeza deos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0</td>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "      <td>0</td>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1</td>\n",
              "      <td>Me aburro</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0</td>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ...                                            text_v2\n",
              "0  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...  ...  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...\n",
              "1  —Vamos Luke desenfunda tu sable, demuestra tu ...  ...  —Vamos Luke desenfunda tu sable, demuestra tu ...\n",
              "2  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...  ...  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...\n",
              "3              No se porqué me hago la cabeza deooos  ...                No se porqué me hago la cabeza deos\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...  Quisiera saber que hago durante la siesta de l...\n",
              "5  La persona que te dice que no se arrepiente de...  ...  La persona que te dice que no se arrepiente de...\n",
              "6  —Buenas don Pepe, ¿me vende un litro de leche?...  ...  —Buenas don Pepe, ¿me vende un litro de leche?...\n",
              "7                                       Meeee aburro  ...                                          Me aburro\n",
              "8  Macri le dijo las gordas que usar calzas está ...  ...  Macri le dijo las gordas que usar calzas está ...\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...                      JAVIER CHICALITO HERNANDEZ *7\n",
              "\n",
              "[10 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 478
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "Zlw1G7Q9CzVv",
        "outputId": "ae893dce-b559-4afd-ad3d-139252514f2d"
      },
      "source": [
        "def get_corpus_translation(corpus):\n",
        "  from transformers import pipeline\n",
        "  pline = pipeline(\"translation_es_to_en\", model=model, tokenizer=tokenizer)\n",
        "\n",
        "  def get_tweet_translation(tweet):\n",
        "    return pline(tweet.replace('.', '<point>'))[0]['translation_text']\n",
        "\n",
        "  return list(map(get_tweet_translation, corpus['text_v2'].to_list()))\n",
        "\n",
        "text['en_text'] = get_corpus_translation(text)\n",
        "\n",
        "text = text[['text', 'text_v2', 'en_text', 'len_token', 'n_char', 'ratio', 'detected_cansinos']]\n",
        "text"
      ],
      "execution_count": 479,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>text_v2</th>\n",
              "      <th>en_text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>Mental retardation levels: — Low&lt;point&gt; — Medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>\"Come on, Luke, unscrew your saber, show your ...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>- Do I offer you something?, Water, coffee, my...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>No se porqué me hago la cabeza deos</td>\n",
              "      <td>I don't know why I'm doing my head.</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>I'd like to know what I do during the nap from...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>La persona que te dice que no se arrepiente de...</td>\n",
              "      <td>The person who tells you that he doesn't regre...</td>\n",
              "      <td>26</td>\n",
              "      <td>120</td>\n",
              "      <td>0.216667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "      <td>\"Good Don Pepe, will you sell me a liter of mi...</td>\n",
              "      <td>19</td>\n",
              "      <td>112</td>\n",
              "      <td>0.169643</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Meeee aburro</td>\n",
              "      <td>Me aburro</td>\n",
              "      <td>I'm bored.</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>0.166667</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>Macri le dijo las gordas que usar calzas está ...</td>\n",
              "      <td>Macri told the fat ones that wearing socks is ...</td>\n",
              "      <td>10</td>\n",
              "      <td>51</td>\n",
              "      <td>0.196078</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>JAVIER CHICALITO HERNANDEZ *7</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>0.137931</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  ... detected_cansinos\n",
              "0  Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...  ...                 0\n",
              "1  —Vamos Luke desenfunda tu sable, demuestra tu ...  ...                 0\n",
              "2  - ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...  ...                 1\n",
              "3              No se porqué me hago la cabeza deooos  ...                 1\n",
              "4  Quisiera saber que hago durante la siesta de l...  ...                 0\n",
              "5  La persona que te dice que no se arrepiente de...  ...                 0\n",
              "6  —Buenas don Pepe, ¿me vende un litro de leche?...  ...                 0\n",
              "7                                       Meeee aburro  ...                 1\n",
              "8  Macri le dijo las gordas que usar calzas está ...  ...                 0\n",
              "9                      JAVIER CHICALITO HERNANDEZ *7  ...                 0\n",
              "\n",
              "[10 rows x 7 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 479
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbrUBiTrX93k"
      },
      "source": [
        "**I'm bored** antes se traducía como **meeee bored**, así que hemos ganado en calidad.\n",
        "\n",
        "Generar a partir de text_v2, text_v3 donde se pase text_v2 y se haga el spell_checker\n",
        "\n",
        "# Pendiente lo último: spell checker "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxLKPcNSYuGc"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}