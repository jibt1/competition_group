{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "CESP_Regresion_DistilBertTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_G9DuJXklWp"
      },
      "source": [
        "https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "\n",
        "https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "\n",
        "https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "\n",
        "https://stackoverflow.com/questions/51093691/custom-activation-function-keras-applying-different-activation-to-different-lay"
      ],
      "id": "j_G9DuJXklWp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdBmYUeGDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "733ec01f-2a8e-4d88-d287-b3f10d00fa9d"
      },
      "source": [
        "# Comprobamos si est√° tensorflow-gpu==2.3.0\n",
        "!pip freeze"
      ],
      "id": "HUdBmYUeGDMC",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "cftime==1.4.1\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==8.0.0\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==7.4.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.264\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.2\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.30.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.32.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.3\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.0.1\n",
            "importlib-resources==5.1.2\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==2.0.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.1.3.1\n",
            "Keras==2.4.3\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "knnimpute==0.1.0\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.0\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "np-utils==0.5.12.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.18.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.10.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==1.7.3\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.4\n",
            "rsa==4.7.2\n",
            "sacremoses==0.0.45\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.3\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.0.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.3.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.15\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "stop-words==2018.7.23\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.4.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.4.1\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.3.0\n",
            "tensorflow-gcs-config==2.4.0\n",
            "tensorflow-gpu==2.3.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==0.30.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.9.5\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.4.8\n",
            "tokenizers==0.9.4\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "transformers==4.2.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==2.0.0\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.0\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKT4OMu1GTXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29f131ef-89f9-4ea1-bf2f-dc3477607bcf"
      },
      "source": [
        "# Esta es la tarjeta grafica\n",
        "!nvidia-smi"
      ],
      "id": "GKT4OMu1GTXu",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tue May 25 10:31:48 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P0    27W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5eE7XLbUfs"
      },
      "source": [
        "# instalar librer√≠as. Esta casilla es √∫ltil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrar√≠an ya instaladas\n",
        "\n",
        "%%capture\n",
        "# Librer√≠√≠a transformers\n",
        "try:\n",
        "    import tranformers\n",
        "    print(\"module 'tranformers' is installed\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"module 'transformers' is being installed\")\n",
        "    !pip install transformers==4.2.1\n",
        "# Por si se quiere usar la gpu verificamos si tenemos transformers-gpu\n",
        "import sys\n",
        "if \"tensorflow-gpu\" in sys.modules:\n",
        "    print(\"tensorflow-gpu already in sys.modules\")\n",
        "else: \n",
        "  !pip install tensorflow-gpu==2.3.0"
      ],
      "id": "9E5eE7XLbUfs",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR8cCMhop_4_",
        "outputId": "371d8e10-c1ac-4815-a217-b76e568cc36a"
      },
      "source": [
        "!pip install tensorflow-gpu==2.3.0"
      ],
      "id": "rR8cCMhop_4_",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.4.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.36.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (56.1.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.30.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.4)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.3.4)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.0.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertConfig, TFDistilBertModel, DistilBertTokenizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "# Para trabajar teniendo encuenta el desbalanceo\n",
        "from sklearn.utils import class_weight\n",
        "import os\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0",
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 226
        },
        "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
        "outputId": "11823ffd-0f31-4a68-d8ea-79cacc317196"
      },
      "source": [
        "train_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/haha_2021_train.csv\", sep=',')\n",
        "# According to https://www.fing.edu.uy/inco/grupos/pln/haha/\n",
        "# we have to assume it is a joke so we can filter by humorous tweets\n",
        "train_dataframe = train_dataframe.query('is_humor == 1')\n",
        "train_dataframe.head(6)"
      ],
      "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>votes_no</th>\n",
              "      <th>votes_1</th>\n",
              "      <th>votes_2</th>\n",
              "      <th>votes_3</th>\n",
              "      <th>votes_4</th>\n",
              "      <th>votes_5</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_mechanism</th>\n",
              "      <th>humor_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tweet7</td>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tweet13</td>\n",
              "      <td>#20CosasQueHacerAntesDeMorir: Ense√±arles la di...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>reference</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tweet14</td>\n",
              "      <td>Le√≠ que la falta de sexo trae consigo una nota...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... humor_target\n",
              "0    tweet1  ...          NaN\n",
              "1    tweet2  ...          NaN\n",
              "2    tweet3  ...          NaN\n",
              "6    tweet7  ...          NaN\n",
              "12  tweet13  ...          NaN\n",
              "13  tweet14  ...          NaN\n",
              "\n",
              "[6 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IkYJX5IpGzK"
      },
      "source": [
        "# Creo un conjunto de validaci√≥n con data splitting\n",
        "train, val = train_test_split(train_dataframe, test_size=.15)"
      ],
      "id": "1IkYJX5IpGzK",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO724yCyKWja"
      },
      "source": [
        "x_train = train['text']\n",
        "y_train = train['humor_rating']\n",
        "x_val = val['text']\n",
        "y_val = val['humor_rating']"
      ],
      "id": "oO724yCyKWja",
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1a262d-af41-4b0a-a58e-404511e53795"
      },
      "source": [
        "cfg = {}\n",
        "cfg[\"framework\"] = \"tf\"\n",
        "cfg[\"max_length\"] = 256 # 380 caracteros maximo por tweet (Mirar maximo de longitud)\n",
        "cfg[\"transformer_model_name\"] = \"dccuchile/bert-base-spanish-wwm-cased\" # Este es el modelo Bert para Spanish, con mayusculas\n",
        "cfg[\"num_labels\"] = 1"
      ],
      "id": "2a1a262d-af41-4b0a-a58e-404511e53795",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb353e76-024b-420e-bc93-4db2832b1478"
      },
      "source": [
        "# dim dimension del pooling layer de los outputs del encoder en la salida de la ultima capa\n",
        "# https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "# https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n",
        "# dropout es el dropout de las denses de las capas de encoders\n",
        "# seq_classif_dropout es el dropout de la ultima densa ajena a Bert\n",
        "# Reducimos la complejidad del problema, solo tenemos 25000 tweets\n",
        "\n",
        "# cargar el tokenizador, disponible en Transformers\n",
        "cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['transformer_model_name'] )\n",
        "\n",
        "# instanciar y entrenar LabelBinarizer\n",
        "#cfg['label_binarizer'] = preprocessing.LabelBinarizer() # guardar para su posterior uso al decodificar predicciones\n",
        "\n",
        "config_bert = DistilBertConfig(attention_dropout=0.6, dropout=0.6,\n",
        "                               n_heads=2, dim=32, max_position_embeddings=cfg[\"max_length\"],\n",
        "                               n_layers=2, hidden_dim=64, vocab_size=cfg['tokenizer'].vocab_size, output_hidden_states=True)\n",
        "# model = TFDistilBertModel.from_pretrained(cfg[\"transformer_model_name\"], config=config_bert)"
      ],
      "id": "bb353e76-024b-420e-bc93-4db2832b1478",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG5ZpwHrEiJJ",
        "outputId": "56a98357-ccae-4ac8-80b1-cb460861e898"
      },
      "source": [
        "cfg['tokenizer'].vocab_size"
      ],
      "id": "NG5ZpwHrEiJJ",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6usKj7q0ES"
      },
      "source": [
        "# ML Keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU, ReLU, Activation, Dropout, Conv1D, Reshape, Flatten, MaxPooling1D, Lambda, Concatenate\n",
        "from tensorflow.keras.activations import softmax, tanh, sigmoid, relu\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n"
      ],
      "id": "zt6usKj7q0ES",
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY7uOGJeoCkf",
        "outputId": "c5b04bc2-fe4f-47bc-ce95-3c4b84b1b596"
      },
      "source": [
        "# Permite obtener las stop_words de los idiomas soportados\n",
        "!pip install stop_words"
      ],
      "id": "CY7uOGJeoCkf",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbPg6kNKoJrH",
        "outputId": "c3fb6bd8-c6f0-45f0-e438-3bb5300d172f"
      },
      "source": [
        "from stop_words import get_stop_words # Se a√±ade librer√≠a para obtener las stop_word de cualquier idioma\n",
        "!wget \"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\""
      ],
      "id": "dbPg6kNKoJrH",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-25 10:32:03--  https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.111.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10258 (10K) [application/octet-stream]\n",
            "Saving to: ‚Äòmore_stop_words.txt.2‚Äô\n",
            "\n",
            "\rmore_stop_words.txt   0%[                    ]       0  --.-KB/s               \rmore_stop_words.txt 100%[===================>]  10.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-25 10:32:03 (106 MB/s) - ‚Äòmore_stop_words.txt.2‚Äô saved [10258/10258]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPRAeSoQoRPw"
      },
      "source": [
        "# Se obtienen las stop_words en espa√±ol\n",
        "import pickle\n",
        "with open(\"more_stop_words.txt\", \"rb\") as f:\n",
        "  list_test = pickle.load(f)\n",
        "\n",
        "stop_words = get_stop_words(\"spanish\")\n",
        "more_stop_words = stop_words + list_test\n",
        "more_stop_words.sort()"
      ],
      "id": "tPRAeSoQoRPw",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3RjR4Zon4Iz"
      },
      "source": [
        "from nltk.stem.snowball import SpanishStemmer\n",
        "def spanish_stemmer(sentence):\n",
        "    stemmer = SpanishStemmer()\n",
        "    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=more_stop_words,\n",
        "                               ngram_range=(1, 1)).build_analyzer()\n",
        "    return (stemmer.stem(word) for word in analyzer(sentence))"
      ],
      "id": "J3RjR4Zon4Iz",
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTA5XWd6ogQW",
        "outputId": "b8edf3e2-7059-43c1-b3cc-f2d389eb298e"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
        "c_vec = CountVectorizer(analyzer=spanish_stemmer, stop_words=more_stop_words)\n",
        "# tf_idf = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "c_vec_mat = c_vec.fit_transform(x_train)\n",
        "# tf_idf_mat = tf_idf.fit_transform(c_vec_mat)\n",
        "c_vec_mat.shape"
      ],
      "id": "sTA5XWd6ogQW",
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7865, 9185)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi-WaXbZ3J7y",
        "outputId": "46dd6e34-61d6-4b43-8848-1c46585634df"
      },
      "source": [
        "df_c_vec = pd.DataFrame(c_vec_mat.toarray(), columns=c_vec.get_feature_names())\n",
        "print(df_c_vec)"
      ],
      "id": "Gi-WaXbZ3J7y",
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      00h  0_0  12456x  1245x‚Öú  138  ...  ŸÅŸäÿ≥  ŸÖÿßcualqui  ŸÖÿ¥ÿ∫ŸàŸàŸÇŸÅ  Êàë‰∏çÊòéÁôΩÈÄôÊàë‰∏çÊòéÁôΩÈÄô  ÔΩáÔΩâÔΩçÔΩâo\n",
            "0       0    0       0       0    0  ...    0          0        0           0      0\n",
            "1       0    0       0       0    0  ...    0          0        0           0      0\n",
            "2       0    0       0       0    0  ...    0          0        0           0      0\n",
            "3       0    0       0       0    0  ...    0          0        0           0      0\n",
            "4       0    0       0       0    0  ...    0          0        0           0      0\n",
            "...   ...  ...     ...     ...  ...  ...  ...        ...      ...         ...    ...\n",
            "7860    0    0       0       0    0  ...    0          0        0           0      0\n",
            "7861    0    0       0       0    0  ...    0          0        0           0      0\n",
            "7862    0    0       0       0    0  ...    0          0        0           0      0\n",
            "7863    0    0       0       0    0  ...    0          0        0           0      0\n",
            "7864    0    0       0       0    0  ...    0          0        0           0      0\n",
            "\n",
            "[7865 rows x 9185 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr_0_onemC0A"
      },
      "source": [
        "class CustomDistilBERTModel():\n",
        "    def __init__(self, cfg, config_bert):\n",
        "\n",
        "          # Configuraciones\n",
        "          self.cgf = cfg\n",
        "          self.config_bert = config_bert\n",
        "          \n",
        "          # Instanciamos DistilBertModel\n",
        "          self.DistilBert = TFDistilBertModel.from_pretrained(self.cgf[\"transformer_model_name\"],\n",
        "                                                      config=self.config_bert)\n",
        "          self.DistilBert_model = None\n",
        "\n",
        "    def custom_activation(self, sigma):\n",
        "      # https://stackoverflow.com/questions/51093691/custom-activation-function-keras-applying-different-activation-to-different-lay\n",
        "      return 4*sigma+1\n",
        "\n",
        "    \"\"\"def custom_activation_shape(self, input_shape):\n",
        "        # Ensure there is rank 4 tensor\n",
        "        assert len(input_shape) == 4\n",
        "        # Ensure the last input component has 5 dimensions\n",
        "        assert input_shape[3] == 5\n",
        "\n",
        "        return input_shape  # Shape is unchanged\"\"\"\n",
        "\n",
        "    def get_model_inputs(self, cfg, data):\n",
        "        encodings = cfg['tokenizer'](data, truncation=True, padding='max_length', max_length=cfg['max_length'], return_tensors=cfg['framework'])\n",
        "        inputs = {'input_ids': encodings['input_ids'],\n",
        "                'attention_mask': encodings['attention_mask']\n",
        "                }\n",
        "        return inputs\n",
        "\n",
        "    def DistilBertNN(self):#, ids, mask):\n",
        "          # https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "          # https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "          input_ids = Input(shape=(256, ),dtype='int32')\n",
        "          attention_mask = Input(shape=(256, ), dtype='int32')\n",
        "          word_context = Input(shape=(c_vec_mat.shape[1],), dtype='int32')\n",
        "\n",
        "          # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertmodel\n",
        "\n",
        "          output_bert = self.DistilBert(\n",
        "                                    input_ids=input_ids, \n",
        "                                    attention_mask=attention_mask\n",
        "                                    )\n",
        "\n",
        "          \"\"\"\n",
        "          last_hidden_state, 1 tensor\n",
        "          hidden_states, 3 tensores (n_layers = 2 + entrada)\n",
        "          attention = None (en principio)\n",
        "          \"\"\"\n",
        "          output_bert = output_bert['hidden_states']\n",
        "          \"\"\"\n",
        "          (batch_size, longitud_secuencia, profundidad de las capas FF intermedias)\n",
        "          (batch_size, max_position_embeddings, dim=32)\n",
        "          \"\"\"\n",
        "\n",
        "          # Probar tambien sumando\n",
        "          output_bert = Concatenate()(output_bert)\n",
        "          #dense = MaxPooling1D(pool_size=1)(output_bert)\n",
        "          dense = Flatten()(output_bert)\n",
        "          \n",
        "          \"\"\"dense2 = Reshape( (-1,1) )(word_context)\n",
        "          dense2 = MaxPooling1D(pool_size=2)(dense2)\n",
        "          dense2 = Flatten()(dense2)\"\"\"\n",
        "          dense2 = Dense(128)(word_context)\n",
        "\n",
        "          dense = Concatenate()([dense, dense2])\n",
        "\n",
        "          dense = Dense(64)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = LeakyReLU()(dense)\n",
        "          dense = Dropout(0.4)(dense)\n",
        "          dense = Dense(32)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = relu(dense)\n",
        "          dense = Dropout(0.2)(dense)\n",
        "\n",
        "          dense = Dense(1)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = sigmoid(dense)\n",
        "          output = Lambda(self.custom_activation, \n",
        "                          output_shape=(None,1))(dense)\n",
        "\n",
        "          ### Output\n",
        "          model = Model([input_ids, attention_mask, word_context], output)\n",
        "\n",
        "          ### Cross Entropy y Optimizador Adam\n",
        "          model.compile(optimizer=\"SGD\", loss=\"mse\", metrics=['mae', tf.keras.metrics.RootMeanSquaredError()])\n",
        "          model.summary()\n",
        "\n",
        "          self.DistilBert_model = model\n",
        "\n",
        "    def train_model(self, x_train, y_train, x_val, y_val):\n",
        "        \"\"\"\n",
        "        M√©todo que entrena el modelo.\n",
        "\n",
        "        Args:\n",
        "\n",
        "        * x_train: matriz de dise√±o\n",
        "        * y_train: target codificada\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        tokens + attention_mask\n",
        "        \"\"\"\n",
        "        print(x_train.shape)\n",
        "        train_word_context = c_vec.fit_transform(x_train)\n",
        "        val_word_context = c_vec.transform(x_val)\n",
        "\n",
        "        self.DistilBertNN()\n",
        "        \n",
        "        train_inputs = self.get_model_inputs(cfg, x_train.to_list())\n",
        "        val_inputs = self.get_model_inputs(cfg, x_val.to_list())\n",
        "\n",
        "        # obtener tensores correspondientes\n",
        "        train_blabels_t = tf.convert_to_tensor(y_train, dtype='int32')\n",
        "        val_blabels_t = tf.convert_to_tensor(y_val, dtype='int32')\n",
        "\n",
        "        # Instancio el m√©√©todo earlyStopping para no perseverar en el entrenamiento si\n",
        "        # se obtiene una mejora tras una paciencia de 8 iteraciones\n",
        "        \"\"\"earlyStopping = EarlyStopping(monitor='val_accuracy', patience=8, verbose=0, mode='max')\"\"\"\n",
        "\n",
        "        # Creo un guardado del mejor modelo visto hasta el fin del entrenamiento monitorizando\n",
        "        # el val_accuracy\n",
        "        \"\"\"checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True)\"\"\"\n",
        "\n",
        "        # Ajusto el modelo con 50 epocas controladas por earlyStopiing y batch size de 50\n",
        "        self.DistilBert_model.fit([train_inputs['input_ids'], train_inputs['attention_mask'], train_word_context.toarray()],  train_blabels_t, \n",
        "                  batch_size = 32, epochs = 10,\n",
        "                  verbose = 1,\n",
        "                  # callbacks=[earlyStopping, checkpoint],\n",
        "                  validation_data=([val_inputs['input_ids'], val_inputs['attention_mask'], val_word_context.toarray()], val_blabels_t))\n",
        "        #plt.hist(self.DistilBert_model.predict([train_inputs['input_ids'], train_inputs['attention_mask']]))"
      ],
      "id": "qr_0_onemC0A",
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjaLpWCc9sPe",
        "outputId": "fcfabfba-11ba-41f6-f8d0-b79f52cfeb1f"
      },
      "source": [
        "instancia = CustomDistilBERTModel(cfg, config_bert)\n",
        "#instancia.DistilBertNN()"
      ],
      "id": "cjaLpWCc9sPe",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFDistilBertModel: ['bert', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['distilbert']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXQM5aT4-Sqf",
        "outputId": "187d718e-c6e1-448f-9496-521a1a26e7d3"
      },
      "source": [
        "instancia.train_model(x_train, y_train, x_val, y_val)"
      ],
      "id": "dXQM5aT4-Sqf",
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7865,)\n",
            "WARNING:tensorflow:AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f62ce7656e0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <bound method Socket.send of <zmq.sugar.socket.Socket object at 0x7f62ce7656e0>> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: module, class, method, function, traceback, frame, or code object was expected, got cython_function_or_method\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:AutoGraph could not transform <function wrap at 0x7f62e38efd40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: AutoGraph could not transform <function wrap at 0x7f62e38efd40> and will run it as-is.\n",
            "Cause: while/else statement not yet supported\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "Model: \"functional_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model (TFDistilB TFBaseModelOutput(la 1017408     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 256, 96)      0           tf_distil_bert_model[0][0]       \n",
            "                                                                 tf_distil_bert_model[0][1]       \n",
            "                                                                 tf_distil_bert_model[0][3]       \n",
            "__________________________________________________________________________________________________\n",
            "input_3 (InputLayer)            [(None, 9185)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 24576)        0           concatenate[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          1175808     input_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 24704)        0           flatten[0][0]                    \n",
            "                                                                 dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 64)           1581120     concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 64)           256         dense_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu (LeakyReLU)         (None, 64)           0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dropout_7 (Dropout)             (None, 64)           0           leaky_re_lu[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 32)           2080        dropout_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 32)           128         dense_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu (TensorFlowOpL [(None, 32)]         0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_8 (Dropout)             (None, 32)           0           tf_op_layer_Relu[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_3 (Dense)                 (None, 1)            33          dropout_8[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 1)            4           dense_3[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sigmoid (TensorFlow [(None, 1)]          0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "lambda (Lambda)                 (None, 1)            0           tf_op_layer_Sigmoid[0][0]        \n",
            "==================================================================================================\n",
            "Total params: 3,776,837\n",
            "Trainable params: 3,776,643\n",
            "Non-trainable params: 194\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "244/246 [============================>.] - ETA: 0s - loss: 0.7890 - mae: 0.6983 - root_mean_squared_error: 0.8883"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "246/246 [==============================] - 5s 19ms/step - loss: 0.7867 - mae: 0.6975 - root_mean_squared_error: 0.8869 - val_loss: 0.4263 - val_mae: 0.5568 - val_root_mean_squared_error: 0.6529\n",
            "Epoch 2/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4494 - mae: 0.5810 - root_mean_squared_error: 0.6704 - val_loss: 0.4202 - val_mae: 0.5682 - val_root_mean_squared_error: 0.6482\n",
            "Epoch 3/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4478 - mae: 0.5848 - root_mean_squared_error: 0.6691 - val_loss: 0.4200 - val_mae: 0.5697 - val_root_mean_squared_error: 0.6480\n",
            "Epoch 4/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4476 - mae: 0.5860 - root_mean_squared_error: 0.6690 - val_loss: 0.4196 - val_mae: 0.5683 - val_root_mean_squared_error: 0.6478\n",
            "Epoch 5/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4481 - mae: 0.5854 - root_mean_squared_error: 0.6694 - val_loss: 0.4198 - val_mae: 0.5699 - val_root_mean_squared_error: 0.6480\n",
            "Epoch 6/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4480 - mae: 0.5860 - root_mean_squared_error: 0.6693 - val_loss: 0.4198 - val_mae: 0.5696 - val_root_mean_squared_error: 0.6479\n",
            "Epoch 7/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4470 - mae: 0.5853 - root_mean_squared_error: 0.6685 - val_loss: 0.4191 - val_mae: 0.5677 - val_root_mean_squared_error: 0.6474\n",
            "Epoch 8/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4471 - mae: 0.5845 - root_mean_squared_error: 0.6686 - val_loss: 0.4191 - val_mae: 0.5687 - val_root_mean_squared_error: 0.6474\n",
            "Epoch 9/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4478 - mae: 0.5851 - root_mean_squared_error: 0.6691 - val_loss: 0.4193 - val_mae: 0.5692 - val_root_mean_squared_error: 0.6475\n",
            "Epoch 10/10\n",
            "246/246 [==============================] - 4s 16ms/step - loss: 0.4477 - mae: 0.5857 - root_mean_squared_error: 0.6691 - val_loss: 0.4192 - val_mae: 0.5691 - val_root_mean_squared_error: 0.6475\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPa1EtYlKpgz"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ],
      "id": "wPa1EtYlKpgz"
    }
  ]
}