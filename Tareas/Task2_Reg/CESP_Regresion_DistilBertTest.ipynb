{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "CESP_Regresión_DistilBertTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_G9DuJXklWp"
      },
      "source": [
        "https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "\n",
        "https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "\n",
        "https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "\n",
        "https://stackoverflow.com/questions/51093691/custom-activation-function-keras-applying-different-activation-to-different-lay"
      ],
      "id": "j_G9DuJXklWp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdBmYUeGDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6297c0c-cce4-4798-dcad-0cd5778a4efa"
      },
      "source": [
        "# Comprobamos si está tensorflow-gpu==2.3.0\n",
        "!pip freeze"
      ],
      "id": "HUdBmYUeGDMC",
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "arviz==0.11.2\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.4.0\n",
            "attrs==21.2.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.1\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.2\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==4.2.2\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "cftime==1.4.1\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==8.0.0\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==7.4.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.23\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17.1\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.264\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.1.0\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.2\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.30.0\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.1.0\n",
            "grpcio==1.32.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.3\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==4.0.1\n",
            "importlib-resources==5.1.2\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==2.0.0\n",
            "jax==0.2.13\n",
            "jaxlib==0.1.66+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.1.3.1\n",
            "Keras==2.4.3\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "knnimpute==0.1.0\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==2.0.0\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "netCDF4==1.5.6\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "np-utils==0.5.12.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.18.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.3\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.9\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.10.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.2.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==1.7.3\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.11.2\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.4\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==5.0.2\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.4\n",
            "rsa==4.7.2\n",
            "sacremoses==0.0.45\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.3\n",
            "seaborn==0.11.1\n",
            "semver==2.13.0\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.0.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.3.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.15\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "stop-words==2018.7.23\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.4.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.4.1\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.3.0\n",
            "tensorflow-gcs-config==2.4.0\n",
            "tensorflow-gpu==2.3.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==0.30.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.9.5\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano-PyMC==1.1.2\n",
            "thinc==7.4.0\n",
            "tifffile==2021.4.8\n",
            "tokenizers==0.9.4\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "transformers==4.2.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==2.0.0\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.18.0\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKT4OMu1GTXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e39e7a-0afc-4e88-b920-1ed28c609097"
      },
      "source": [
        "# Esta es la tarjeta grafica\n",
        "!nvidia-smi"
      ],
      "id": "GKT4OMu1GTXu",
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sat May 15 17:03:58 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   73C    P0    75W / 149W |   8450MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5eE7XLbUfs"
      },
      "source": [
        "# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n",
        "\n",
        "%%capture\n",
        "# Libreríía transformers\n",
        "try:\n",
        "    import tranformers\n",
        "    print(\"module 'tranformers' is installed\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"module 'transformers' is being installed\")\n",
        "    !pip install transformers==4.2.1\n",
        "# Por si se quiere usar la gpu verificamos si tenemos transformers-gpu\n",
        "import sys\n",
        "if \"tensorflow-gpu\" in sys.modules:\n",
        "    print(\"tensorflow-gpu already in sys.modules\")\n",
        "else: \n",
        "  !pip install tensorflow-gpu==2.3.0"
      ],
      "id": "9E5eE7XLbUfs",
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rR8cCMhop_4_",
        "outputId": "556a548a-6205-4e1e-fe07-47fc5fcbfb42"
      },
      "source": [
        "!pip install tensorflow-gpu==2.3.0"
      ],
      "id": "rR8cCMhop_4_",
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu==2.3.0 in /usr/local/lib/python3.7/dist-packages (2.3.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.36.2)\n",
            "Requirement already satisfied: tensorboard<3,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.4.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.3.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.0)\n",
            "Requirement already satisfied: h5py<2.11.0,>=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.10.0)\n",
            "Requirement already satisfied: astunparse==1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.6.3)\n",
            "Requirement already satisfied: keras-preprocessing<1.2,>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.1.2)\n",
            "Requirement already satisfied: numpy<1.19.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.18.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (3.12.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.2.0)\n",
            "Requirement already satisfied: tensorflow-estimator<2.4.0,>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (2.3.0)\n",
            "Requirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.4.1)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (1.12.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.12.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu==2.3.0) (0.3.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.30.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.23.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (56.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.8.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.4)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.0.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (2.10)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (4.0.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (0.4.8)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<3,>=2.3.0->tensorflow-gpu==2.3.0) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertConfig, TFDistilBertModel, DistilBertTokenizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "# Para trabajar teniendo encuenta el desbalanceo\n",
        "from sklearn.utils import class_weight\n",
        "import os\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0",
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
        "outputId": "b6bbfe1d-4810-47e3-9c32-95b8b4c8d28d"
      },
      "source": [
        "train_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/haha_2021_train.csv\", sep=',')\n",
        "# According to https://www.fing.edu.uy/inco/grupos/pln/haha/\n",
        "# we have to assume it is a joke so we can filter by humorous tweets\n",
        "train_dataframe = train_dataframe.query('is_humor == 1')\n",
        "train_dataframe.head(6)"
      ],
      "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>votes_no</th>\n",
              "      <th>votes_1</th>\n",
              "      <th>votes_2</th>\n",
              "      <th>votes_3</th>\n",
              "      <th>votes_4</th>\n",
              "      <th>votes_5</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_mechanism</th>\n",
              "      <th>humor_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tweet7</td>\n",
              "      <td>—Buenas don Pepe, ¿me vende un litro de leche?...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tweet13</td>\n",
              "      <td>#20CosasQueHacerAntesDeMorir: Enseñarles la di...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>reference</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tweet14</td>\n",
              "      <td>Leí que la falta de sexo trae consigo una nota...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... humor_target\n",
              "0    tweet1  ...          NaN\n",
              "1    tweet2  ...          NaN\n",
              "2    tweet3  ...          NaN\n",
              "6    tweet7  ...          NaN\n",
              "12  tweet13  ...          NaN\n",
              "13  tweet14  ...          NaN\n",
              "\n",
              "[6 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 126
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1IkYJX5IpGzK"
      },
      "source": [
        "# Creo un conjunto de validación con data splitting\n",
        "train, val = train_test_split(train_dataframe, test_size=.15)"
      ],
      "id": "1IkYJX5IpGzK",
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO724yCyKWja"
      },
      "source": [
        "x_train = train['text']\n",
        "y_train = train['humor_rating']\n",
        "x_val = val['text']\n",
        "y_val = val['humor_rating']"
      ],
      "id": "oO724yCyKWja",
      "execution_count": 128,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1a262d-af41-4b0a-a58e-404511e53795"
      },
      "source": [
        "cfg = {}\n",
        "cfg[\"framework\"] = \"tf\"\n",
        "cfg[\"max_length\"] = 256 # 380 caracteros maximo por tweet (Mirar maximo de longitud)\n",
        "cfg[\"transformer_model_name\"] = \"dccuchile/bert-base-spanish-wwm-cased\" # Este es el modelo Bert para Spanish, con mayusculas\n",
        "cfg[\"num_labels\"] = 1"
      ],
      "id": "2a1a262d-af41-4b0a-a58e-404511e53795",
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb353e76-024b-420e-bc93-4db2832b1478"
      },
      "source": [
        "# dim dimension del pooling layer de los outputs del encoder en la salida de la ultima capa\n",
        "# https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "# https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n",
        "# dropout es el dropout de las denses de las capas de encoders\n",
        "# seq_classif_dropout es el dropout de la ultima densa ajena a Bert\n",
        "# Reducimos la complejidad del problema, solo tenemos 25000 tweets\n",
        "\n",
        "# cargar el tokenizador, disponible en Transformers\n",
        "cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['transformer_model_name'] )\n",
        "\n",
        "# instanciar y entrenar LabelBinarizer\n",
        "#cfg['label_binarizer'] = preprocessing.LabelBinarizer() # guardar para su posterior uso al decodificar predicciones\n",
        "\n",
        "config_bert = DistilBertConfig(attention_dropout=0.6, dropout=0.6,\n",
        "                               n_heads=2, dim=32, max_position_embeddings=cfg[\"max_length\"],\n",
        "                               n_layers=2, hidden_dim=64, vocab_size=cfg['tokenizer'].vocab_size, output_hidden_states=True)\n",
        "# model = TFDistilBertModel.from_pretrained(cfg[\"transformer_model_name\"], config=config_bert)"
      ],
      "id": "bb353e76-024b-420e-bc93-4db2832b1478",
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG5ZpwHrEiJJ",
        "outputId": "b50b6c8d-445f-4097-afe7-173e259edd3b"
      },
      "source": [
        "cfg['tokenizer'].vocab_size"
      ],
      "id": "NG5ZpwHrEiJJ",
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6usKj7q0ES"
      },
      "source": [
        "# ML Keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU, ReLU, Activation, Dropout, Conv1D, Reshape, Flatten, MaxPooling1D, Lambda, Concatenate\n",
        "from tensorflow.keras.activations import softmax, tanh, sigmoid, relu\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n"
      ],
      "id": "zt6usKj7q0ES",
      "execution_count": 132,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CY7uOGJeoCkf",
        "outputId": "365c6e11-c391-40eb-9d57-7eaeaf5103cb"
      },
      "source": [
        "# Permite obtener las stop_words de los idiomas soportados\n",
        "!pip install stop_words"
      ],
      "id": "CY7uOGJeoCkf",
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: stop_words in /usr/local/lib/python3.7/dist-packages (2018.7.23)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbPg6kNKoJrH",
        "outputId": "2d4a18ca-191c-4f48-ca02-f2bc7afba6e5"
      },
      "source": [
        "from stop_words import get_stop_words # Se añade librería para obtener las stop_word de cualquier idioma\n",
        "!wget \"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\""
      ],
      "id": "dbPg6kNKoJrH",
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-15 17:04:15--  https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10258 (10K) [application/octet-stream]\n",
            "Saving to: ‘more_stop_words.txt.3’\n",
            "\n",
            "more_stop_words.txt 100%[===================>]  10.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-15 17:04:15 (71.3 MB/s) - ‘more_stop_words.txt.3’ saved [10258/10258]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPRAeSoQoRPw"
      },
      "source": [
        "# Se obtienen las stop_words en español\n",
        "import pickle\n",
        "with open(\"more_stop_words.txt\", \"rb\") as f:\n",
        "  list_test = pickle.load(f)\n",
        "\n",
        "stop_words = get_stop_words(\"spanish\")\n",
        "more_stop_words = stop_words + list_test\n",
        "more_stop_words.sort()"
      ],
      "id": "tPRAeSoQoRPw",
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3RjR4Zon4Iz"
      },
      "source": [
        "from nltk.stem.snowball import SpanishStemmer\n",
        "def spanish_stemmer(sentence):\n",
        "    stemmer = SpanishStemmer()\n",
        "    analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=more_stop_words,\n",
        "                               ngram_range=(1, 1)).build_analyzer()\n",
        "    return (stemmer.stem(word) for word in analyzer(sentence))"
      ],
      "id": "J3RjR4Zon4Iz",
      "execution_count": 136,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTA5XWd6ogQW",
        "outputId": "71b1023c-d7e2-4fbe-fcf3-434c3b82062d"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfTransformer, TfidfVectorizer, CountVectorizer\n",
        "c_vec = CountVectorizer(analyzer=spanish_stemmer, stop_words=more_stop_words)\n",
        "# tf_idf = TfidfTransformer(smooth_idf=True, use_idf=True)\n",
        "c_vec_mat = c_vec.fit_transform(x_train)\n",
        "# tf_idf_mat = tf_idf.fit_transform(c_vec_mat)\n",
        "c_vec_mat.shape"
      ],
      "id": "sTA5XWd6ogQW",
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7865, 9190)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gi-WaXbZ3J7y",
        "outputId": "4d377a8c-6cf3-4976-fc75-cd526526c224"
      },
      "source": [
        "df_c_vec = pd.DataFrame(c_vec_mat.toarray(), columns=c_vec.get_feature_names())\n",
        "print(df_c_vec)"
      ],
      "id": "Gi-WaXbZ3J7y",
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      00h  100tific  10defectosmi  ...  مشغووقف  我不明白這我不明白這  ｇｉｍｉo\n",
            "0       0         0             0  ...        0           0      0\n",
            "1       0         0             0  ...        0           0      0\n",
            "2       0         0             0  ...        0           0      0\n",
            "3       0         0             0  ...        0           0      0\n",
            "4       0         0             0  ...        0           0      0\n",
            "...   ...       ...           ...  ...      ...         ...    ...\n",
            "7860    0         0             0  ...        0           0      0\n",
            "7861    0         0             0  ...        0           0      0\n",
            "7862    0         0             0  ...        0           0      0\n",
            "7863    0         0             0  ...        0           0      0\n",
            "7864    0         0             0  ...        0           0      0\n",
            "\n",
            "[7865 rows x 9190 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr_0_onemC0A"
      },
      "source": [
        "class CustomDistilBERTModel():\n",
        "    def __init__(self, cfg, config_bert):\n",
        "\n",
        "          # Configuraciones\n",
        "          self.cgf = cfg\n",
        "          self.config_bert = config_bert\n",
        "          \n",
        "          # Instanciamos DistilBertModel\n",
        "          self.DistilBert = TFDistilBertModel.from_pretrained(self.cgf[\"transformer_model_name\"],\n",
        "                                                      config=self.config_bert)\n",
        "          self.DistilBert_model = None\n",
        "\n",
        "    def custom_activation(self, sigma):\n",
        "      # https://stackoverflow.com/questions/51093691/custom-activation-function-keras-applying-different-activation-to-different-lay\n",
        "      return 4*sigma+1\n",
        "\n",
        "    \"\"\"def custom_activation_shape(self, input_shape):\n",
        "        # Ensure there is rank 4 tensor\n",
        "        assert len(input_shape) == 4\n",
        "        # Ensure the last input component has 5 dimensions\n",
        "        assert input_shape[3] == 5\n",
        "\n",
        "        return input_shape  # Shape is unchanged\"\"\"\n",
        "\n",
        "    def get_model_inputs(self, cfg, data):\n",
        "        encodings = cfg['tokenizer'](data, truncation=True, padding='max_length', max_length=cfg['max_length'], return_tensors=cfg['framework'])\n",
        "        inputs = {'input_ids': encodings['input_ids'],\n",
        "                'attention_mask': encodings['attention_mask']\n",
        "                }\n",
        "        return inputs\n",
        "\n",
        "    def DistilBertNN(self):#, ids, mask):\n",
        "          # https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "          # https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "          input_ids = Input(shape=(256, ),dtype='int32')\n",
        "          attention_mask = Input(shape=(256, ), dtype='int32')\n",
        "          word_context = Input(shape=(c_vec_mat.shape[1],), dtype='int32')\n",
        "\n",
        "          # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertmodel\n",
        "\n",
        "          output_bert = self.DistilBert(\n",
        "                                    input_ids=input_ids, \n",
        "                                    attention_mask=attention_mask\n",
        "                                    )\n",
        "\n",
        "          \"\"\"\n",
        "          last_hidden_state, 1 tensor\n",
        "          hidden_states, 3 tensores (n_layers = 2 + entrada)\n",
        "          attention = None (en principio)\n",
        "          \"\"\"\n",
        "          output_bert = output_bert['hidden_states']\n",
        "          \"\"\"\n",
        "          (batch_size, longitud_secuencia, profundidad de las capas FF intermedias)\n",
        "          (batch_size, max_position_embeddings, dim=32)\n",
        "          \"\"\"\n",
        "\n",
        "          # Probar tambien sumando\n",
        "          output_bert = Concatenate()(output_bert)\n",
        "          #dense = MaxPooling1D(pool_size=1)(output_bert)\n",
        "          dense = Flatten()(output_bert)\n",
        "          \n",
        "          \"\"\"dense2 = Reshape( (-1,1) )(word_context)\n",
        "          dense2 = MaxPooling1D(pool_size=2)(dense2)\n",
        "          dense2 = Flatten()(dense2)\"\"\"\n",
        "          dense2 = Dense(128)(word_context)\n",
        "\n",
        "          dense = Concatenate()([dense, dense2])\n",
        "\n",
        "          dense = Dense(64)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = LeakyReLU()(dense)\n",
        "          dense = Dropout(0.4)(dense)\n",
        "          dense = Dense(32)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = relu(dense)\n",
        "          dense = Dropout(0.2)(dense)\n",
        "\n",
        "          dense = Dense(1)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = sigmoid(dense)\n",
        "          output = Lambda(self.custom_activation, \n",
        "                          output_shape=(None,1))(dense)\n",
        "\n",
        "          ### Output\n",
        "          model = Model([input_ids, attention_mask, word_context], output)\n",
        "\n",
        "          ### Cross Entropy y Optimizador Adam\n",
        "          model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae', tf.keras.metrics.RootMeanSquaredError()])\n",
        "          model.summary()\n",
        "\n",
        "          self.DistilBert_model = model\n",
        "\n",
        "    def train_model(self, x_train, y_train, x_val, y_val):\n",
        "        \"\"\"\n",
        "        Método que entrena el modelo.\n",
        "\n",
        "        Args:\n",
        "\n",
        "        * x_train: matriz de diseño\n",
        "        * y_train: target codificada\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        tokens + attention_mask\n",
        "        \"\"\"\n",
        "        print(x_train.shape)\n",
        "        train_word_context = c_vec.fit_transform(x_train)\n",
        "        val_word_context = c_vec.transform(x_val)\n",
        "\n",
        "        self.DistilBertNN()\n",
        "        \n",
        "        train_inputs = self.get_model_inputs(cfg, x_train.to_list())\n",
        "        val_inputs = self.get_model_inputs(cfg, x_val.to_list())\n",
        "\n",
        "        # obtener tensores correspondientes\n",
        "        train_blabels_t = tf.convert_to_tensor(y_train, dtype='int32')\n",
        "        val_blabels_t = tf.convert_to_tensor(y_val, dtype='int32')\n",
        "\n",
        "        # Instancio el méétodo earlyStopping para no perseverar en el entrenamiento si\n",
        "        # se obtiene una mejora tras una paciencia de 8 iteraciones\n",
        "        \"\"\"earlyStopping = EarlyStopping(monitor='val_accuracy', patience=8, verbose=0, mode='max')\"\"\"\n",
        "\n",
        "        # Creo un guardado del mejor modelo visto hasta el fin del entrenamiento monitorizando\n",
        "        # el val_accuracy\n",
        "        \"\"\"checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True)\"\"\"\n",
        "\n",
        "        # Ajusto el modelo con 50 epocas controladas por earlyStopiing y batch size de 50\n",
        "        self.DistilBert_model.fit([train_inputs['input_ids'], train_inputs['attention_mask'], train_word_context.toarray()],  train_blabels_t, \n",
        "                  batch_size = 32, epochs = 10,\n",
        "                  verbose = 1,\n",
        "                  # callbacks=[earlyStopping, checkpoint],\n",
        "                  validation_data=([val_inputs['input_ids'], val_inputs['attention_mask'], val_word_context.toarray()], val_blabels_t))\n",
        "        #plt.hist(self.DistilBert_model.predict([train_inputs['input_ids'], train_inputs['attention_mask']]))"
      ],
      "id": "qr_0_onemC0A",
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjaLpWCc9sPe",
        "outputId": "141e7847-4c28-4418-9799-d8775e8bfa00"
      },
      "source": [
        "instancia = CustomDistilBERTModel(cfg, config_bert)\n",
        "#instancia.DistilBertNN()"
      ],
      "id": "cjaLpWCc9sPe",
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFDistilBertModel: ['bert', 'mlm___cls']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['distilbert']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dXQM5aT4-Sqf",
        "outputId": "08e8b8b8-ded7-4690-eb97-701646b5db27"
      },
      "source": [
        "instancia.train_model(x_train, y_train, x_val, y_val)"
      ],
      "id": "dXQM5aT4-Sqf",
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(7865,)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"functional_47\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_106 (InputLayer)          [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_107 (InputLayer)          [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model_31 (TFDist TFBaseModelOutput(la 1017408     input_106[0][0]                  \n",
            "                                                                 input_107[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_61 (Concatenate)    (None, 256, 96)      0           tf_distil_bert_model_31[0][0]    \n",
            "                                                                 tf_distil_bert_model_31[0][1]    \n",
            "                                                                 tf_distil_bert_model_31[0][3]    \n",
            "__________________________________________________________________________________________________\n",
            "input_108 (InputLayer)          [(None, 9190)]       0                                            \n",
            "__________________________________________________________________________________________________\n",
            "flatten_40 (Flatten)            (None, 24576)        0           concatenate_61[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_96 (Dense)                (None, 128)          1176448     input_108[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_62 (Concatenate)    (None, 24704)        0           flatten_40[0][0]                 \n",
            "                                                                 dense_96[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_97 (Dense)                (None, 64)           1581120     concatenate_62[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 64)           256         dense_97[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 64)           0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_270 (Dropout)           (None, 64)           0           leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_98 (Dense)                (None, 32)           2080        dropout_270[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 32)           128         dense_98[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Relu_23 (TensorFlow [(None, 32)]         0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_271 (Dropout)           (None, 32)           0           tf_op_layer_Relu_23[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_99 (Dense)                (None, 1)            33          dropout_271[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 1)            4           dense_99[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_Sigmoid_23 (TensorF [(None, 1)]          0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_23 (Lambda)              (None, 1)            0           tf_op_layer_Sigmoid_23[0][0]     \n",
            "==================================================================================================\n",
            "Total params: 3,777,477\n",
            "Trainable params: 3,777,283\n",
            "Non-trainable params: 194\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "246/246 [==============================] - ETA: 0s - loss: 2.4226 - mae: 1.3051 - root_mean_squared_error: 1.5565"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "246/246 [==============================] - 10s 41ms/step - loss: 2.4226 - mae: 1.3051 - root_mean_squared_error: 1.5565 - val_loss: 2.6869 - val_mae: 1.3915 - val_root_mean_squared_error: 1.6392\n",
            "Epoch 2/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 1.6841 - mae: 1.0769 - root_mean_squared_error: 1.2977 - val_loss: 1.0086 - val_mae: 0.8536 - val_root_mean_squared_error: 1.0043\n",
            "Epoch 3/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 1.1065 - mae: 0.8916 - root_mean_squared_error: 1.0519 - val_loss: 1.0339 - val_mae: 0.8594 - val_root_mean_squared_error: 1.0168\n",
            "Epoch 4/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.7304 - mae: 0.7274 - root_mean_squared_error: 0.8547 - val_loss: 0.7918 - val_mae: 0.7374 - val_root_mean_squared_error: 0.8898\n",
            "Epoch 5/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.5291 - mae: 0.6116 - root_mean_squared_error: 0.7274 - val_loss: 0.6618 - val_mae: 0.6581 - val_root_mean_squared_error: 0.8135\n",
            "Epoch 6/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.4014 - mae: 0.5265 - root_mean_squared_error: 0.6335 - val_loss: 0.5479 - val_mae: 0.5930 - val_root_mean_squared_error: 0.7402\n",
            "Epoch 7/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.3154 - mae: 0.4670 - root_mean_squared_error: 0.5616 - val_loss: 0.5582 - val_mae: 0.6055 - val_root_mean_squared_error: 0.7471\n",
            "Epoch 8/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.2561 - mae: 0.4237 - root_mean_squared_error: 0.5060 - val_loss: 0.5172 - val_mae: 0.5895 - val_root_mean_squared_error: 0.7192\n",
            "Epoch 9/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.2076 - mae: 0.3835 - root_mean_squared_error: 0.4557 - val_loss: 0.4954 - val_mae: 0.5805 - val_root_mean_squared_error: 0.7039\n",
            "Epoch 10/10\n",
            "246/246 [==============================] - 9s 38ms/step - loss: 0.1806 - mae: 0.3596 - root_mean_squared_error: 0.4249 - val_loss: 0.4856 - val_mae: 0.5758 - val_root_mean_squared_error: 0.6969\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPa1EtYlKpgz"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ],
      "id": "wPa1EtYlKpgz"
    }
  ]
}