{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "CESP_DistilBertClassification_NoColbert.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdBmYUeGDMC"
      },
      "source": [
        "# Comprobamos si está tensorflow-gpu==2.3.0\n",
        "# !pip freeze"
      ],
      "id": "HUdBmYUeGDMC",
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WHL_g1jGFbUd"
      },
      "source": [
        "# Hay que instalar esto si se quiere utilizar la gpu\n",
        "#!pip install tensorflow-gpu==2.3.0 "
      ],
      "id": "WHL_g1jGFbUd",
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKT4OMu1GTXu"
      },
      "source": [
        "# Esta es la tarjeta grafica\n",
        "# !nvidia-smi"
      ],
      "id": "GKT4OMu1GTXu",
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNpuCz8aEjPe"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Instalamos las librerías necesarias"
      ],
      "id": "dNpuCz8aEjPe"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5eE7XLbUfs"
      },
      "source": [
        "# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n",
        "%%capture\n",
        "!pip install transformers==4.2.1\n",
        "# !pip install tensorflow-gpu==2.3.0\n",
        "!pip install stop_words\n",
        "print('Done!')"
      ],
      "id": "9E5eE7XLbUfs",
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "id": "-d3ClrqWDxa-",
        "outputId": "f1c9ae6a-02c2-4e0e-e8f9-e30bead588dc"
      },
      "source": [
        "# instalar librerías. Esta casilla es últil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrarían ya instaladas\n",
        "\n",
        "\"\"\"%%capture\n",
        "# Librería transformers\n",
        "try:\n",
        "    import tranformers\n",
        "    print(\"module 'tranformers' is installed\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"module 'transformers' is being installed\")\n",
        "    !pip install transformers==4.2.1\n",
        "# Por si se quiere usar la gpu verificamos si tenemos transformers-gpu\n",
        "import sys\n",
        "if \"tensorflow-gpu\" in sys.modules:\n",
        "    print(\"tensorflow-gpu already in sys.modules\")\n",
        "else: \n",
        "  !pip install tensorflow-gpu==2.3.0\"\"\""
      ],
      "id": "-d3ClrqWDxa-",
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'%%capture\\n# Librería transformers\\ntry:\\n    import tranformers\\n    print(\"module \\'tranformers\\' is installed\")\\nexcept ModuleNotFoundError:\\n    print(\"module \\'transformers\\' is being installed\")\\n    !pip install transformers==4.2.1\\n# Por si se quiere usar la gpu verificamos si tenemos transformers-gpu\\nimport sys\\nif \"tensorflow-gpu\" in sys.modules:\\n    print(\"tensorflow-gpu already in sys.modules\")\\nelse: \\n  !pip install tensorflow-gpu==2.3.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2NPJ8lDOEoGK"
      },
      "source": [
        "---\n",
        "---"
      ],
      "id": "2NPJ8lDOEoGK"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LVktqmesEhFK"
      },
      "source": [
        "# Importamos librerías"
      ],
      "id": "LVktqmesEhFK"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0"
      },
      "source": [
        "#%reset\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertConfig, DistilBertTokenizer, TFDistilBertModel\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "# Para trabajar teniendo encuenta el desbalanceo\n",
        "from sklearn.utils import class_weight\n",
        "import os\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "\n",
        "# Librerías para la matriz word context\n",
        "from nltk.stem.snowball import SpanishStemmer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from stop_words import get_stop_words # Se añade librería para obtener las stop_word de cualquier idioma\n",
        "import pickle\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
      ],
      "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0",
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMU7HV9rFKH_"
      },
      "source": [
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU, Activation, Dropout, Conv1D, Reshape, Flatten, MaxPooling1D, Concatenate\n",
        "from tensorflow.keras.activations import softmax, tanh, sigmoid, relu\n",
        "from tensorflow.keras.models import Model"
      ],
      "id": "CMU7HV9rFKH_",
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mq-xlx-Ep_x"
      },
      "source": [
        "---\n",
        "---"
      ],
      "id": "1mq-xlx-Ep_x"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOCrlcheEbmM"
      },
      "source": [
        "# Cargamos los datos"
      ],
      "id": "XOCrlcheEbmM"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
        "outputId": "b98214b8-8701-4dda-9126-97e1de4e75be"
      },
      "source": [
        "cleaned_corpus = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/task_preproceso/Super_Final_versionV3/cleaned_corpus.csv\", sep=',')\n",
        "cleaned_corpus = cleaned_corpus[~cleaned_corpus.text_v5.isna()]\n",
        "print(cleaned_corpus.shape)\n",
        "cleaned_corpus.head()"
      ],
      "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(23984, 28)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>text_v2</th>\n",
              "      <th>text_v3</th>\n",
              "      <th>text_v4</th>\n",
              "      <th>text_v5</th>\n",
              "      <th>en_text</th>\n",
              "      <th>len_token</th>\n",
              "      <th>n_char</th>\n",
              "      <th>ratio</th>\n",
              "      <th>detected_cansinos</th>\n",
              "      <th>detected_emojis_cansinos</th>\n",
              "      <th>detected_text_cansinos</th>\n",
              "      <th>text_emojis</th>\n",
              "      <th>HasNoun</th>\n",
              "      <th>HasAdj</th>\n",
              "      <th>HasVerb</th>\n",
              "      <th>PoSTags</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>votes_no</th>\n",
              "      <th>votes_1</th>\n",
              "      <th>votes_2</th>\n",
              "      <th>votes_3</th>\n",
              "      <th>votes_4</th>\n",
              "      <th>votes_5</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_mechanism</th>\n",
              "      <th>humor_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n— Bajo.\\n— Medi...</td>\n",
              "      <td>Niveles de retraso mental  .  Bajo .  .  Medio...</td>\n",
              "      <td>Niveles de retraso mental  .  Bajo .  .  Medio...</td>\n",
              "      <td>mental retardation levels  .  low  .   .  medi...</td>\n",
              "      <td>19</td>\n",
              "      <td>86</td>\n",
              "      <td>0.220930</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>NOUN ADP NOUN ADJ SPACE PUNCT SPACE PROPN PUNC...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>—Vamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>. Vamos Luke desenfunda tu sable demuestra tu...</td>\n",
              "      <td>. Vamos Luke desenfunda tu sable demuestra tu...</td>\n",
              "      <td>.  let's luke unscrew your sabre shows your h...</td>\n",
              "      <td>22</td>\n",
              "      <td>140</td>\n",
              "      <td>0.157143</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>SPACE PUNCT VERB PROPN VERB DET NOUN VERB DET ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>- ¿Te ofrezco algo?, ¿Agua, café, mi corazón, ...</td>\n",
              "      <td>-  ¿ Te ofrezco algo ? ,  ¿ agua café mi coraz...</td>\n",
              "      <td>-  ¿ Te ofrezco algo ? ,  ¿ agua café mi coraz...</td>\n",
              "      <td>- Do I offer you anything? , do I water coffee...</td>\n",
              "      <td>21</td>\n",
              "      <td>112</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>PUNCT SPACE PUNCT PRON VERB PRON PUNCT PUNCT S...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.6</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tweet4</td>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>No se porqué me hago la cabeza deooos</td>\n",
              "      <td>No se porqué me hago la cabeza deos</td>\n",
              "      <td>No se porqué me hago la cabeza deos</td>\n",
              "      <td>No se porqué me hago la cabeza deos</td>\n",
              "      <td>I don't know why I'm doing my head.</td>\n",
              "      <td>8</td>\n",
              "      <td>37</td>\n",
              "      <td>0.216216</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>ADV PRON VERB PRON VERB DET NOUN ADJ</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>tweet5</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>Quisiera saber que hago durante la siesta de l...</td>\n",
              "      <td>I want to know what I do during the nap from w...</td>\n",
              "      <td>20</td>\n",
              "      <td>106</td>\n",
              "      <td>0.188679</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>no_emojis</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>VERB AUX SCONJ VERB ADP DET NOUN ADP DET PRON ...</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id  ... humor_target\n",
              "0  tweet1  ...          NaN\n",
              "1  tweet2  ...          NaN\n",
              "2  tweet3  ...          NaN\n",
              "3  tweet4  ...          NaN\n",
              "4  tweet5  ...          NaN\n",
              "\n",
              "[5 rows x 28 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-P_2ehnmiPL"
      },
      "source": [
        "#test_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/datasets/haha_2021_dev.csv\", sep=',')"
      ],
      "id": "U-P_2ehnmiPL",
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8W7jze5pFFah"
      },
      "source": [
        "---\n",
        "---"
      ],
      "id": "8W7jze5pFFah"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWxhSWb_E9JB"
      },
      "source": [
        "# Métricas para el entrenamiento"
      ],
      "id": "OWxhSWb_E9JB"
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QVYxWP6TsPjF",
        "outputId": "59798dc5-5f76-4106-9437-7839b3474cdb"
      },
      "source": [
        "!pip install tensorflow_addons\n",
        "import tensorflow_addons as tfa "
      ],
      "id": "QVYxWP6TsPjF",
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_addons in /usr/local/lib/python3.7/dist-packages (0.13.0)\n",
            "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow_addons) (2.7.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bce9e6a-cb3f-41fe-92f1-c8bc4b3e6c8f"
      },
      "source": [
        "# Se definen metricas\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision"
      ],
      "id": "6bce9e6a-cb3f-41fe-92f1-c8bc4b3e6c8f",
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qip4EXzpFEIM"
      },
      "source": [
        "---\n",
        "---"
      ],
      "id": "qip4EXzpFEIM"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6JBYJXhSEtNI"
      },
      "source": [
        "# Establecemos la configuración de DistilBert"
      ],
      "id": "6JBYJXhSEtNI"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb353e76-024b-420e-bc93-4db2832b1478"
      },
      "source": [
        "# https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "# https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n",
        "# dim dimension del pooling layer de los outputs del encoder en la salida de la ultima capa\n",
        "# dropout es el dropout de las denses de las capas de encoders\n",
        "# seq_classif_dropout es el dropout de la ultima densa ajena a Bert (top dense)"
      ],
      "id": "bb353e76-024b-420e-bc93-4db2832b1478",
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vvVluezFhNV"
      },
      "source": [
        "---\n",
        "---\n",
        "\n",
        "# Clase Modelo Fine Tuning"
      ],
      "id": "9vvVluezFhNV"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fd87i71XFh9l"
      },
      "source": [
        "class CustomDistilBERTModel():\n",
        "    \"\"\"\n",
        "    Se crea una clase con todo lo necesario para construir nuestro modelo\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, cleaned_corpus, stop_words):\n",
        "          \"\"\"\n",
        "          Atributos:\n",
        "\n",
        "          cleaned_corpus (df): corpus tratado a partir del ipynb con el Preprocesado de Datos\n",
        "                               `PreprocesadoTextos_SuperFinalV.ipynb`\n",
        "\n",
        "          stop_words (list): lista con las palabras que se quieren excluir del conocimiento específico\n",
        "          \"\"\"\n",
        "\n",
        "          #### Configuración del modelo ####\n",
        "\n",
        "          # cfg (dict): diccionario con los datos generales que configuran el modelo DistilBert\n",
        "          self.cfg = {}\n",
        "          self.cfg[\"framework\"] = \"tf\" # Tensorflow\n",
        "          self.cfg[\"max_length\"] = 256\n",
        "          # Modelo Bert para Spanish\n",
        "          self.cfg[\"transformer_model_name\"] = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
        "          # El problema es binario pero en lugar de una neurona utilizo 2 neuronas\n",
        "          self.cfg[\"num_labels\"] = 2\n",
        "\n",
        "          # Cargamos el tokenizador correspondiente ¿Lematiza?\n",
        "          self.cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(self.cfg['transformer_model_name'],\n",
        "                                                                      output_attentions=True, return_dict=True)\n",
        "          # Proceso de scikit learn para hacer OHE a 0 1 de la salida\n",
        "          self.cfg['label_binarizer'] = preprocessing.LabelBinarizer()\n",
        "\n",
        "          # config_bert (dict): diccionario con los datos que filtran y disminuyen las capas de DistilBert\n",
        "          self.config_bert = DistilBertConfig(num_labels = self.cfg[\"num_labels\"], \n",
        "                              attention_dropout=0.75, seq_classif_dropout=0, dropout=0.75,\n",
        "                              n_heads=4, dim=64, max_position_embeddings=self.cfg[\"max_length\"],\n",
        "                              n_layers=2, hidden_dim=128, vocab_size=self.cfg['tokenizer'].vocab_size,\n",
        "                              output_hidden_states=True)\n",
        "          \n",
        "          # Instanciamos DistilBertModel\n",
        "          self.DistilBert = TFDistilBertModel.from_pretrained(self.cfg[\"transformer_model_name\"],\n",
        "                                                      config=self.config_bert)\n",
        "          # Futuro modelo keras\n",
        "          self.humor_model = None\n",
        "\n",
        "          # Corpus\n",
        "          self.corpus = cleaned_corpus\n",
        "\n",
        "          # Stop Words\n",
        "          self.stop_words = stop_words\n",
        "\n",
        "          # Count Vectorizer\n",
        "          self.c_vec = CountVectorizer(analyzer=self.spanish_stemmer, stop_words=self.stop_words, lowercase=True)\n",
        "\n",
        "    def spanish_stemmer(self, sentence):\n",
        "        \"\"\"\n",
        "        Método para obtener el lema de cada token del corpus\n",
        "\n",
        "        Args:\n",
        "          sentence: tweet en formato string\n",
        "        \"\"\"\n",
        "\n",
        "        stemmer = SpanishStemmer()\n",
        "        analyzer = CountVectorizer(binary=False, analyzer='word', stop_words=self.stop_words,\n",
        "                                  ngram_range=(1, 1)).build_analyzer()\n",
        "        return (stemmer.stem(word) for word in analyzer(sentence))\n",
        "        \n",
        "    def get_word_context_matrix(self):\n",
        "        \"\"\"\n",
        "        Método que obtiene la matriz word_context para un corpus dado\n",
        "\n",
        "        Args:\n",
        "          which_text: cualesquiera de los pd.Series del corpus con acceso:\n",
        "                  text, text_v1, text_v2, text_v3, text_v4, text_v5\n",
        "        \"\"\"\n",
        "        self.word_context_matrix = self.c_vec.fit_transform(self.x_train[self.which_text].to_list())\n",
        "        # self.save_object(self.count_vectorizer, \"pickle_count_vectorizer\")\n",
        "        #return word_context_matrix\n",
        "\n",
        "    def get_model_inputs(self, is_val=False):\n",
        "        \"\"\"\n",
        "        Método que obtiene los inputs_ids (mapeo del vocabulario) y las máscaras\n",
        "        de atención. Ambos son inputs necesarios para el modelo de Bert\n",
        "        \"\"\"\n",
        "        if is_val==False:\n",
        "          corpus_list = self.x_train[self.which_text].to_list()\n",
        "        else:\n",
        "          corpus_list = self.x_val[self.which_text].to_list()\n",
        "        \n",
        "        encodings = self.cfg['tokenizer'](corpus_list, truncation=True, padding='max_length',\n",
        "                                          max_length=self.cfg['max_length'], return_tensors=self.cfg['framework'])\n",
        "        inputs = {'input_ids': encodings['input_ids'],\n",
        "                'attention_mask': encodings['attention_mask']\n",
        "                }\n",
        "        return inputs\n",
        "\n",
        "    def prepare_inputs(self, which_text, which_target):\n",
        "        \"\"\"\n",
        "        Método que prepara los inputs de entrada\n",
        "        \"\"\"\n",
        "        self.which_text = which_text\n",
        "        self.which_target = which_target\n",
        "        self.get_word_context_matrix()\n",
        "        self.get_model_inputs()\n",
        "\n",
        "    def DistilBert_extension(self):#, ids, mask):\n",
        "        \"\"\"\n",
        "        Método que crea la arquitectura y su correspondiente flujo y que, además,\n",
        "        compila dicha arquitectura\n",
        "        \"\"\"\n",
        "\n",
        "        input_ids = Input(shape=(256, ),dtype='int32')\n",
        "        attention_mask = Input(shape=(256, ), dtype='int32')\n",
        "        word_context = Input(shape=(self.word_context_matrix.shape[1],), dtype='int32')\n",
        "\n",
        "        # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertmodel\n",
        "\n",
        "        output_bert = self.DistilBert(\n",
        "                                  input_ids=input_ids, \n",
        "                                  attention_mask=attention_mask\n",
        "                                  )\n",
        "\n",
        "        \"\"\"\n",
        "        last_hidden_state, 1 tensor\n",
        "        hidden_states, 3 tensores (n_layers = 2 + entrada)\n",
        "        attention = None (en principio)\n",
        "        \"\"\"\n",
        "        # output_bert = output_bert['hidden_states']\n",
        "        output_bert = output_bert['last_hidden_state'][:,0,:]\n",
        "        \"\"\"\n",
        "        (batch_size, longitud_secuencia, profundidad de las capas FF intermedias)\n",
        "        (batch_size, max_position_embeddings, dim=32)\n",
        "        \"\"\"\n",
        "\n",
        "        # output_bert = Concatenate()(output_bert)\n",
        "\n",
        "        # flatten_bert = Flatten()(output_bert)\n",
        "\n",
        "        dense_word_context = Dense(128)(word_context)\n",
        "\n",
        "        dense = Concatenate()([output_bert, dense_word_context])\n",
        "\n",
        "        dense = Dense(64)(dense)\n",
        "        dense = BatchNormalization()(dense)\n",
        "        dense = LeakyReLU()(dense)\n",
        "        dense = Dropout(0.4)(dense)\n",
        "        dense = Dense(32)(dense)\n",
        "        dense = BatchNormalization()(dense)\n",
        "        dense = relu(dense)\n",
        "        dense = Dropout(0.2)(dense)\n",
        "\n",
        "        output = Dense(2, activation='softmax')(dense)\n",
        "\n",
        "        ### Output\n",
        "        model = Model([input_ids, attention_mask, word_context], output)\n",
        "\n",
        "        ### Cross Entropy y Optimizador Adam\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "        loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True)\n",
        "\n",
        "        # Compilación del modelo\n",
        "        model.compile(optimizer=optimizer, loss=loss, metrics=[tfa.metrics.F1Score(2, 'macro'),  'accuracy'])\n",
        "        model.summary()\n",
        "\n",
        "        self.humor_model = model\n",
        "\n",
        "    def train_model(self, which_text='text_v5', which_target='is_humor', pval=0):\n",
        "        \"\"\"\n",
        "        Método que entrena el modelo.\n",
        "\n",
        "        Args:\n",
        "\n",
        "        * input_ids:\n",
        "        * attention_mask:\n",
        "        * word_context\n",
        "        \"\"\"\n",
        "\n",
        "        if pval < 0 or pval >= 1:\n",
        "          raise ValueError('0 <= pval < 1 es la proporción del conjunto de validación')\n",
        "\n",
        "        if pval > 0:\n",
        "          X = self.corpus\n",
        "          y = self.corpus[[which_target]]\n",
        "          x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=pval, stratify=y)\n",
        "          self.entire_dataset_for_training = False\n",
        "\n",
        "          self.x_train = x_train\n",
        "          self.y_train = y_train\n",
        "          self.x_val = x_val\n",
        "          self.y_val = y_val\n",
        "\n",
        "          # Preparamos los datos\n",
        "          self.prepare_inputs(which_text, which_target)\n",
        "\n",
        "          self.val_word_context = self.c_vec.transform(x_val[self.which_text])\n",
        "\n",
        "          train_blabels = to_categorical(self.y_train)\n",
        "          train_blabels_t = tf.convert_to_tensor(train_blabels, dtype='int32')\n",
        "          val_blabels = to_categorical(y_val)\n",
        "          val_blabels_t = tf.convert_to_tensor(val_blabels, dtype='int32')\n",
        "\n",
        "          train_inputs = self.get_model_inputs()\n",
        "          val_inputs = self.get_model_inputs(is_val=True)\n",
        "\n",
        "          earlyStopping = EarlyStopping(monitor='val_accuracy', patience=8, verbose=0, mode='max')\n",
        "          checkpoint = ModelCheckpoint(\"best_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "\n",
        "          class_weights = class_weight.compute_class_weight('balanced', np.unique(train_blabels), train_blabels.ravel())\n",
        "          class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "          # Compilamos\n",
        "          self.DistilBert_extension()\n",
        "\n",
        "          self.humor_model.fit([train_inputs['input_ids'], train_inputs['attention_mask'], \n",
        "                      self.word_context_matrix.toarray()],  y=train_blabels_t,\n",
        "                      validation_data=([val_inputs['input_ids'], val_inputs['attention_mask'], self.val_word_context.toarray()], val_blabels_t),\n",
        "                      batch_size = 32, epochs = 10,\n",
        "                      verbose = 1, callbacks=[earlyStopping, checkpoint], class_weight=class_weights)\n",
        "        else:\n",
        "          self.x_train = self.corpus\n",
        "          self.y_train = self.corpus[which_target]\n",
        "          train_blabels = to_categorical(self.y_train)\n",
        "          train_blabels_t = tf.convert_to_tensor(train_blabels, dtype='int32')\n",
        "\n",
        "          # Preparamos los datos\n",
        "          self.prepare_inputs(which_text, which_target)\n",
        "\n",
        "          train_inputs = self.get_model_inputs()\n",
        "\n",
        "          class_weights = class_weight.compute_class_weight('balanced', np.unique(train_blabels), train_blabels.ravel())\n",
        "          class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "          # Compilamos\n",
        "          self.DistilBert_extension()\n",
        "          checkpoint = ModelCheckpoint(\"best_model\", monitor=\"val_accuracy\", save_best_only=True)\n",
        "          self.humor_model.fit([train_inputs['input_ids'], train_inputs['attention_mask'], \n",
        "                      self.word_context_matrix.toarray()],  y=train_blabels_t,\n",
        "                      batch_size = 32, epochs = 10,\n",
        "                      verbose = 1, callbacks=[checkpoint], class_weight=class_weights)\n",
        "\n",
        "        # Empleamos el labelizador\n",
        "        #cfg['label_binarizer'].fit(train[\"is_humor\"], num_labels=2)\n",
        "\n",
        "\n",
        "        # Instancio el méétodo earlyStopping para no perseverar en el entrenamiento si\n",
        "        # se obtiene una mejora tras una paciencia de 8 iteraciones\n",
        "        earlyStopping = EarlyStopping(monitor='val_accuracy', patience=8, verbose=0, mode='max')\n",
        "\n",
        "        # Creo un guardado del mejor modelo visto hasta el fin del entrenamiento monitorizando\n",
        "        # el val_accuracy\n",
        "        # checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True)"
      ],
      "id": "fd87i71XFh9l",
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LEnSwsZJeu2X",
        "outputId": "07d3914c-5214-4f5f-93a2-5be7fcdd791e"
      },
      "source": [
        "!wget \"https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\"\n",
        "\n",
        "# Se obtienen las stop_words en español\n",
        "\n",
        "with open(\"more_stop_words.txt\", \"rb\") as f:\n",
        "  list_test = pickle.load(f)\n",
        "\n",
        "stop_words = get_stop_words(\"spanish\")\n",
        "more_stop_words = stop_words + list_test\n",
        "more_stop_words.sort()"
      ],
      "id": "LEnSwsZJeu2X",
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-24 14:33:20--  https://raw.githubusercontent.com/jibt1/competition_group/main/Tareas/datasets/more_stop_words.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10258 (10K) [application/octet-stream]\n",
            "Saving to: ‘more_stop_words.txt.4’\n",
            "\n",
            "\rmore_stop_words.txt   0%[                    ]       0  --.-KB/s               \rmore_stop_words.txt 100%[===================>]  10.02K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-24 14:33:20 (76.7 MB/s) - ‘more_stop_words.txt.4’ saved [10258/10258]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w95l3VvdSgSy",
        "outputId": "79f659e3-2a48-4d71-c08d-7c4c0ec1b028"
      },
      "source": [
        "# Instanciamos el modelo\n",
        "instancia = CustomDistilBERTModel(cleaned_corpus, more_stop_words)"
      ],
      "id": "w95l3VvdSgSy",
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFDistilBertModel: ['mlm___cls', 'bert']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['distilbert']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38frw9hQf2L5",
        "outputId": "a3e2f717-0cf2-456b-dadd-ed90ea2f958b"
      },
      "source": [
        "instancia.train_model(pval=0.15)"
      ],
      "id": "38frw9hQf2L5",
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_14 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model_4 (TFDisti TFBaseModelOutput(la 2067584     input_13[0][0]                   \n",
            "                                                                 input_14[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "input_15 (InputLayer)           [(None, 16180)]      0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf.__operators__.getitem_4 (Sli (None, 64)           0           tf_distil_bert_model_4[0][3]     \n",
            "__________________________________________________________________________________________________\n",
            "dense_16 (Dense)                (None, 128)          2071168     input_15[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 192)          0           tf.__operators__.getitem_4[0][0] \n",
            "                                                                 dense_16[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_17 (Dense)                (None, 64)           12352       concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 64)           256         dense_17[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)       (None, 64)           0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_43 (Dropout)            (None, 64)           0           leaky_re_lu_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_18 (Dense)                (None, 32)           2080        dropout_43[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 32)           128         dense_18[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.relu_4 (TFOpLambda)       (None, 32)           0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "dropout_44 (Dropout)            (None, 32)           0           tf.nn.relu_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_19 (Dense)                (None, 2)            66          dropout_44[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 4,153,634\n",
            "Trainable params: 4,153,442\n",
            "Non-trainable params: 192\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "637/638 [============================>.] - ETA: 0s - loss: 0.8745 - f1_score: 0.5013 - accuracy: 0.5112"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r638/638 [==============================] - 25s 34ms/step - loss: 0.8743 - f1_score: 0.5013 - accuracy: 0.5112 - val_loss: 0.6216 - val_f1_score: 0.3844 - val_accuracy: 0.6156\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n",
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 2/10\n",
            "638/638 [==============================] - 21s 32ms/step - loss: 0.7071 - f1_score: 0.5786 - accuracy: 0.6059 - val_loss: 0.4461 - val_f1_score: 0.7627 - val_accuracy: 0.7740\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 3/10\n",
            "638/638 [==============================] - 21s 32ms/step - loss: 0.5487 - f1_score: 0.7048 - accuracy: 0.7233 - val_loss: 0.4324 - val_f1_score: 0.7964 - val_accuracy: 0.8046\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 4/10\n",
            "638/638 [==============================] - 21s 32ms/step - loss: 0.4918 - f1_score: 0.7496 - accuracy: 0.7679 - val_loss: 0.4170 - val_f1_score: 0.8085 - val_accuracy: 0.8171\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 5/10\n",
            "638/638 [==============================] - 21s 32ms/step - loss: 0.4393 - f1_score: 0.7877 - accuracy: 0.8014 - val_loss: 0.3931 - val_f1_score: 0.8211 - val_accuracy: 0.8313\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 6/10\n",
            "638/638 [==============================] - 20s 31ms/step - loss: 0.4106 - f1_score: 0.8054 - accuracy: 0.8186 - val_loss: 0.3829 - val_f1_score: 0.8272 - val_accuracy: 0.8380\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 7/10\n",
            "638/638 [==============================] - 20s 31ms/step - loss: 0.3770 - f1_score: 0.8224 - accuracy: 0.8344 - val_loss: 0.3797 - val_f1_score: 0.8329 - val_accuracy: 0.8430\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 8/10\n",
            "638/638 [==============================] - 21s 32ms/step - loss: 0.3474 - f1_score: 0.8435 - accuracy: 0.8540 - val_loss: 0.3750 - val_f1_score: 0.8387 - val_accuracy: 0.8502\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 9/10\n",
            "638/638 [==============================] - 20s 32ms/step - loss: 0.3147 - f1_score: 0.8601 - accuracy: 0.8699 - val_loss: 0.3715 - val_f1_score: 0.8441 - val_accuracy: 0.8546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36ddcd10>, because it is not built.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <tensorflow.python.keras.layers.core.Dropout object at 0x7f0c36dde4d0>, because it is not built.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n",
            "WARNING:absl:Found untraced functions such as embeddings_layer_call_fn, embeddings_layer_call_and_return_conditional_losses, transformer_layer_call_fn, transformer_layer_call_and_return_conditional_losses, position_embeddings_layer_call_fn while saving (showing 5 of 160). These functions will not be directly callable after loading.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: best_model/assets\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 10/10\n",
            "638/638 [==============================] - 20s 31ms/step - loss: 0.3002 - f1_score: 0.8689 - accuracy: 0.8776 - val_loss: 0.3758 - val_f1_score: 0.8420 - val_accuracy: 0.8521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mrxCWQg3eAjh"
      },
      "source": [
        "---\n",
        "---"
      ],
      "id": "mrxCWQg3eAjh"
    }
  ]
}