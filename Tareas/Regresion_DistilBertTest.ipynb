{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6"
    },
    "colab": {
      "name": "Regresion_DistilBertTest.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_G9DuJXklWp"
      },
      "source": [
        "https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "\n",
        "https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "\n",
        "https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "\n",
        "https://stackoverflow.com/questions/51093691/custom-activation-function-keras-applying-different-activation-to-different-lay"
      ],
      "id": "j_G9DuJXklWp"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HUdBmYUeGDMC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d1e066c-8121-4b4f-cdf0-bc586b11e96e"
      },
      "source": [
        "# Comprobamos si est√° tensorflow-gpu==2.3.0\n",
        "!pip freeze"
      ],
      "id": "HUdBmYUeGDMC",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absl-py==0.12.0\n",
            "alabaster==0.7.12\n",
            "albumentations==0.1.12\n",
            "altair==4.1.0\n",
            "appdirs==1.4.4\n",
            "argon2-cffi==20.1.0\n",
            "astor==0.8.1\n",
            "astropy==4.2.1\n",
            "astunparse==1.6.3\n",
            "async-generator==1.10\n",
            "atari-py==0.2.6\n",
            "atomicwrites==1.4.0\n",
            "attrs==20.3.0\n",
            "audioread==2.1.9\n",
            "autograd==1.3\n",
            "Babel==2.9.0\n",
            "backcall==0.2.0\n",
            "beautifulsoup4==4.6.3\n",
            "bleach==3.3.0\n",
            "blis==0.4.1\n",
            "bokeh==2.3.1\n",
            "Bottleneck==1.3.2\n",
            "branca==0.4.2\n",
            "bs4==0.0.1\n",
            "CacheControl==0.12.6\n",
            "cachetools==4.2.1\n",
            "catalogue==1.0.0\n",
            "certifi==2020.12.5\n",
            "cffi==1.14.5\n",
            "chainer==7.4.0\n",
            "chardet==3.0.4\n",
            "click==7.1.2\n",
            "cloudpickle==1.3.0\n",
            "cmake==3.12.0\n",
            "cmdstanpy==0.9.5\n",
            "colorcet==2.0.6\n",
            "colorlover==0.3.0\n",
            "community==1.0.0b1\n",
            "contextlib2==0.5.5\n",
            "convertdate==2.3.2\n",
            "coverage==3.7.1\n",
            "coveralls==0.5\n",
            "crcmod==1.7\n",
            "cufflinks==0.17.3\n",
            "cupy-cuda101==7.4.0\n",
            "cvxopt==1.2.6\n",
            "cvxpy==1.0.31\n",
            "cycler==0.10.0\n",
            "cymem==2.0.5\n",
            "Cython==0.29.22\n",
            "daft==0.0.4\n",
            "dask==2.12.0\n",
            "datascience==0.10.6\n",
            "debugpy==1.0.0\n",
            "decorator==4.4.2\n",
            "defusedxml==0.7.1\n",
            "descartes==1.1.0\n",
            "dill==0.3.3\n",
            "distributed==1.25.3\n",
            "dlib==19.18.0\n",
            "dm-tree==0.1.6\n",
            "docopt==0.6.2\n",
            "docutils==0.17\n",
            "dopamine-rl==1.0.5\n",
            "earthengine-api==0.1.260\n",
            "easydict==1.9\n",
            "ecos==2.0.7.post1\n",
            "editdistance==0.5.3\n",
            "en-core-web-sm==2.2.5\n",
            "entrypoints==0.3\n",
            "ephem==3.7.7.1\n",
            "et-xmlfile==1.0.1\n",
            "fa2==0.3.5\n",
            "fancyimpute==0.4.3\n",
            "fastai==1.0.61\n",
            "fastdtw==0.3.4\n",
            "fastprogress==1.0.0\n",
            "fastrlock==0.6\n",
            "fbprophet==0.7.1\n",
            "feather-format==0.4.1\n",
            "filelock==3.0.12\n",
            "firebase-admin==4.4.0\n",
            "fix-yahoo-finance==0.0.22\n",
            "Flask==1.1.2\n",
            "flatbuffers==1.12\n",
            "folium==0.8.3\n",
            "future==0.16.0\n",
            "gast==0.3.3\n",
            "GDAL==2.2.2\n",
            "gdown==3.6.4\n",
            "gensim==3.6.0\n",
            "geographiclib==1.50\n",
            "geopy==1.17.0\n",
            "gin-config==0.4.0\n",
            "glob2==0.7\n",
            "google==2.0.3\n",
            "google-api-core==1.26.3\n",
            "google-api-python-client==1.12.8\n",
            "google-auth==1.28.1\n",
            "google-auth-httplib2==0.0.4\n",
            "google-auth-oauthlib==0.4.4\n",
            "google-cloud-bigquery==1.21.0\n",
            "google-cloud-bigquery-storage==1.1.0\n",
            "google-cloud-core==1.0.3\n",
            "google-cloud-datastore==1.8.0\n",
            "google-cloud-firestore==1.7.0\n",
            "google-cloud-language==1.2.0\n",
            "google-cloud-storage==1.18.1\n",
            "google-cloud-translate==1.5.0\n",
            "google-colab==1.0.0\n",
            "google-pasta==0.2.0\n",
            "google-resumable-media==0.4.1\n",
            "googleapis-common-protos==1.53.0\n",
            "googledrivedownloader==0.4\n",
            "graphviz==0.10.1\n",
            "greenlet==1.0.0\n",
            "grpcio==1.32.0\n",
            "gspread==3.0.1\n",
            "gspread-dataframe==3.0.8\n",
            "gym==0.17.3\n",
            "h5py==2.10.0\n",
            "HeapDict==1.0.1\n",
            "hijri-converter==2.1.1\n",
            "holidays==0.10.5.2\n",
            "holoviews==1.14.3\n",
            "html5lib==1.0.1\n",
            "httpimport==0.5.18\n",
            "httplib2==0.17.4\n",
            "httplib2shim==0.0.3\n",
            "humanize==0.5.1\n",
            "hyperopt==0.1.2\n",
            "ideep4py==2.0.0.post3\n",
            "idna==2.10\n",
            "imageio==2.4.1\n",
            "imagesize==1.2.0\n",
            "imbalanced-learn==0.4.3\n",
            "imblearn==0.0\n",
            "imgaug==0.2.9\n",
            "importlib-metadata==3.10.1\n",
            "importlib-resources==5.1.2\n",
            "imutils==0.5.4\n",
            "inflect==2.1.0\n",
            "iniconfig==1.1.1\n",
            "intel-openmp==2021.2.0\n",
            "intervaltree==2.1.0\n",
            "ipykernel==4.10.1\n",
            "ipython==5.5.0\n",
            "ipython-genutils==0.2.0\n",
            "ipython-sql==0.3.9\n",
            "ipywidgets==7.6.3\n",
            "itsdangerous==1.1.0\n",
            "jax==0.2.12\n",
            "jaxlib==0.1.65+cuda110\n",
            "jdcal==1.4.1\n",
            "jedi==0.18.0\n",
            "jieba==0.42.1\n",
            "Jinja2==2.11.3\n",
            "joblib==1.0.1\n",
            "jpeg4py==0.1.4\n",
            "jsonschema==2.6.0\n",
            "jupyter==1.0.0\n",
            "jupyter-client==5.3.5\n",
            "jupyter-console==5.2.0\n",
            "jupyter-core==4.7.1\n",
            "jupyterlab-pygments==0.1.2\n",
            "jupyterlab-widgets==1.0.0\n",
            "kaggle==1.5.12\n",
            "kapre==0.1.3.1\n",
            "Keras==2.4.3\n",
            "Keras-Preprocessing==1.1.2\n",
            "keras-vis==0.4.1\n",
            "kiwisolver==1.3.1\n",
            "knnimpute==0.1.0\n",
            "korean-lunar-calendar==0.2.1\n",
            "librosa==0.8.0\n",
            "lightgbm==2.2.3\n",
            "llvmlite==0.34.0\n",
            "lmdb==0.99\n",
            "LunarCalendar==0.0.9\n",
            "lxml==4.2.6\n",
            "Markdown==3.3.4\n",
            "MarkupSafe==1.1.1\n",
            "matplotlib==3.2.2\n",
            "matplotlib-inline==0.1.2\n",
            "matplotlib-venn==0.11.6\n",
            "missingno==0.4.2\n",
            "mistune==0.8.4\n",
            "mizani==0.6.0\n",
            "mkl==2019.0\n",
            "mlxtend==0.14.0\n",
            "more-itertools==8.7.0\n",
            "moviepy==0.2.3.5\n",
            "mpmath==1.2.1\n",
            "msgpack==1.0.2\n",
            "multiprocess==0.70.11.1\n",
            "multitasking==0.0.9\n",
            "murmurhash==1.0.5\n",
            "music21==5.5.0\n",
            "natsort==5.5.0\n",
            "nbclient==0.5.3\n",
            "nbconvert==5.6.1\n",
            "nbformat==5.1.3\n",
            "nest-asyncio==1.5.1\n",
            "networkx==2.5.1\n",
            "nibabel==3.0.2\n",
            "nltk==3.2.5\n",
            "notebook==5.3.1\n",
            "np-utils==0.5.12.1\n",
            "numba==0.51.2\n",
            "numexpr==2.7.3\n",
            "numpy==1.18.5\n",
            "nvidia-ml-py3==7.352.0\n",
            "oauth2client==4.1.3\n",
            "oauthlib==3.1.0\n",
            "okgrade==0.4.3\n",
            "opencv-contrib-python==4.1.2.30\n",
            "opencv-python==4.1.2.30\n",
            "openpyxl==2.5.9\n",
            "opt-einsum==3.3.0\n",
            "osqp==0.6.2.post0\n",
            "packaging==20.9\n",
            "palettable==3.3.0\n",
            "pandas==1.1.5\n",
            "pandas-datareader==0.9.0\n",
            "pandas-gbq==0.13.3\n",
            "pandas-profiling==1.4.1\n",
            "pandocfilters==1.4.3\n",
            "panel==0.11.2\n",
            "param==1.10.1\n",
            "parso==0.8.2\n",
            "pathlib==1.0.1\n",
            "patsy==0.5.1\n",
            "pexpect==4.8.0\n",
            "pickleshare==0.7.5\n",
            "Pillow==7.1.2\n",
            "pip-tools==4.5.1\n",
            "plac==1.1.3\n",
            "plotly==4.4.1\n",
            "plotnine==0.6.0\n",
            "pluggy==0.7.1\n",
            "pooch==1.3.0\n",
            "portpicker==1.3.1\n",
            "prefetch-generator==1.0.1\n",
            "preshed==3.0.5\n",
            "prettytable==2.1.0\n",
            "progressbar2==3.38.0\n",
            "prometheus-client==0.10.1\n",
            "promise==2.3\n",
            "prompt-toolkit==1.0.18\n",
            "protobuf==3.12.4\n",
            "psutil==5.4.8\n",
            "psycopg2==2.7.6.1\n",
            "ptyprocess==0.7.0\n",
            "py==1.10.0\n",
            "pyarrow==3.0.0\n",
            "pyasn1==0.4.8\n",
            "pyasn1-modules==0.2.8\n",
            "pycocotools==2.0.2\n",
            "pycparser==2.20\n",
            "pyct==0.4.8\n",
            "pydata-google-auth==1.1.0\n",
            "pydot==1.3.0\n",
            "pydot-ng==2.0.0\n",
            "pydotplus==2.0.2\n",
            "PyDrive==1.3.1\n",
            "pyemd==0.5.1\n",
            "pyerfa==1.7.2\n",
            "pyglet==1.5.0\n",
            "Pygments==2.6.1\n",
            "pygobject==3.26.1\n",
            "pymc3==3.7\n",
            "PyMeeus==0.5.11\n",
            "pymongo==3.11.3\n",
            "pymystem3==0.2.0\n",
            "PyOpenGL==3.1.5\n",
            "pyparsing==2.4.7\n",
            "pyrsistent==0.17.3\n",
            "pysndfile==1.3.8\n",
            "PySocks==1.7.1\n",
            "pystan==2.19.1.1\n",
            "pytest==3.6.4\n",
            "python-apt==0.0.0\n",
            "python-chess==0.23.11\n",
            "python-dateutil==2.8.1\n",
            "python-louvain==0.15\n",
            "python-slugify==4.0.1\n",
            "python-utils==2.5.6\n",
            "pytz==2018.9\n",
            "pyviz-comms==2.0.1\n",
            "PyWavelets==1.1.1\n",
            "PyYAML==3.13\n",
            "pyzmq==22.0.3\n",
            "qdldl==0.1.5.post0\n",
            "qtconsole==5.1.0\n",
            "QtPy==1.9.0\n",
            "regex==2019.12.20\n",
            "requests==2.23.0\n",
            "requests-oauthlib==1.3.0\n",
            "resampy==0.2.2\n",
            "retrying==1.3.3\n",
            "rpy2==3.4.3\n",
            "rsa==4.7.2\n",
            "sacremoses==0.0.45\n",
            "scikit-image==0.16.2\n",
            "scikit-learn==0.22.2.post1\n",
            "scipy==1.4.1\n",
            "screen-resolution-extra==0.0.0\n",
            "scs==2.1.3\n",
            "seaborn==0.11.1\n",
            "Send2Trash==1.5.0\n",
            "setuptools-git==1.2\n",
            "Shapely==1.7.1\n",
            "simplegeneric==0.8.1\n",
            "six==1.15.0\n",
            "sklearn==0.0\n",
            "sklearn-pandas==1.8.0\n",
            "smart-open==5.0.0\n",
            "snowballstemmer==2.1.0\n",
            "sortedcontainers==2.3.0\n",
            "SoundFile==0.10.3.post1\n",
            "spacy==2.2.4\n",
            "Sphinx==1.8.5\n",
            "sphinxcontrib-serializinghtml==1.1.4\n",
            "sphinxcontrib-websupport==1.2.4\n",
            "SQLAlchemy==1.4.7\n",
            "sqlparse==0.4.1\n",
            "srsly==1.0.5\n",
            "statsmodels==0.10.2\n",
            "sympy==1.7.1\n",
            "tables==3.4.4\n",
            "tabulate==0.8.9\n",
            "tblib==1.7.0\n",
            "tensorboard==2.4.1\n",
            "tensorboard-plugin-wit==1.8.0\n",
            "tensorflow==2.4.1\n",
            "tensorflow-datasets==4.0.1\n",
            "tensorflow-estimator==2.3.0\n",
            "tensorflow-gcs-config==2.4.0\n",
            "tensorflow-gpu==2.3.0\n",
            "tensorflow-hub==0.12.0\n",
            "tensorflow-metadata==0.29.0\n",
            "tensorflow-probability==0.12.1\n",
            "termcolor==1.1.0\n",
            "terminado==0.9.4\n",
            "testpath==0.4.4\n",
            "text-unidecode==1.3\n",
            "textblob==0.15.3\n",
            "textgenrnn==1.4.1\n",
            "Theano==1.0.5\n",
            "thinc==7.4.0\n",
            "tifffile==2021.4.8\n",
            "tokenizers==0.9.4\n",
            "toml==0.10.2\n",
            "toolz==0.11.1\n",
            "torch==1.8.1+cu101\n",
            "torchsummary==1.5.1\n",
            "torchtext==0.9.1\n",
            "torchvision==0.9.1+cu101\n",
            "tornado==5.1.1\n",
            "tqdm==4.41.1\n",
            "traitlets==5.0.5\n",
            "transformers==4.2.1\n",
            "tweepy==3.10.0\n",
            "typeguard==2.7.1\n",
            "typing-extensions==3.7.4.3\n",
            "tzlocal==1.5.1\n",
            "uritemplate==3.0.1\n",
            "urllib3==1.24.3\n",
            "vega-datasets==0.9.0\n",
            "wasabi==0.8.2\n",
            "wcwidth==0.2.5\n",
            "webencodings==0.5.1\n",
            "Werkzeug==1.0.1\n",
            "widgetsnbextension==3.5.1\n",
            "wordcloud==1.5.0\n",
            "wrapt==1.12.1\n",
            "xarray==0.15.1\n",
            "xgboost==0.90\n",
            "xkit==0.0.0\n",
            "xlrd==1.1.0\n",
            "xlwt==1.3.0\n",
            "yellowbrick==0.9.1\n",
            "zict==2.0.0\n",
            "zipp==3.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKT4OMu1GTXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b83aeda9-9153-4b93-b27b-b2934cbd801d"
      },
      "source": [
        "# Esta es la tarjeta grafica\n",
        "!nvidia-smi"
      ],
      "id": "GKT4OMu1GTXu",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed May 12 10:52:44 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 465.19.01    Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P0    30W /  70W |   1090MiB / 15109MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9E5eE7XLbUfs"
      },
      "source": [
        "# instalar librer√≠as. Esta casilla es √∫ltil por ejemplo si se ejecuta el cuaderno en Google Colab\n",
        "# Note que existen otras dependencias como tensorflow, etc. que en este caso se encontrar√≠an ya instaladas\n",
        "\n",
        "%%capture\n",
        "# Librer√≠√≠a transformers\n",
        "try:\n",
        "    import tranformers\n",
        "    print(\"module 'tranformers' is installed\")\n",
        "except ModuleNotFoundError:\n",
        "    print(\"module 'transformers' is being installed\")\n",
        "    !pip install transformers==4.2.1\n",
        "# Por si se quiere usar la gpu verificamos si tenemos transformers-gpu\n",
        "import sys\n",
        "if \"tensorflow-gpu\" in sys.modules:\n",
        "    print(\"tensorflow-gpu already in sys.modules\")\n",
        "else: \n",
        "  !pip install tensorflow-gpu==2.3.0"
      ],
      "id": "9E5eE7XLbUfs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0"
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from transformers import DistilBertConfig, TFDistilBertModel, DistilBertTokenizer\n",
        "from sklearn import preprocessing\n",
        "from sklearn.metrics import f1_score\n",
        "# Para trabajar teniendo encuenta el desbalanceo\n",
        "from sklearn.utils import class_weight\n",
        "import os\n",
        "import tqdm\n",
        "import numpy as np\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "id": "fa734488-7dd1-4bf3-a10d-6d571b5d75e0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
        "outputId": "cb8f0475-3c43-480c-dc4e-032678815eaa"
      },
      "source": [
        "train_dataframe = pd.read_csv(\"https://raw.githubusercontent.com/jibt1/competition_group/main/datasets/haha_2021_train.csv\", sep=',')\n",
        "# According to https://www.fing.edu.uy/inco/grupos/pln/haha/\n",
        "# we have to assume it is a joke so we can filter by humorous tweets\n",
        "train_dataframe = train_dataframe.query('is_humor == 1')\n",
        "train_dataframe.head(6)"
      ],
      "id": "38efad68-c786-42d3-b1b2-1a3e43717bcb",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>is_humor</th>\n",
              "      <th>votes_no</th>\n",
              "      <th>votes_1</th>\n",
              "      <th>votes_2</th>\n",
              "      <th>votes_3</th>\n",
              "      <th>votes_4</th>\n",
              "      <th>votes_5</th>\n",
              "      <th>humor_rating</th>\n",
              "      <th>humor_mechanism</th>\n",
              "      <th>humor_target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tweet1</td>\n",
              "      <td>Niveles de retraso mental: \\n\\n‚Äî Bajo.\\n‚Äî Medi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>tweet2</td>\n",
              "      <td>‚ÄîVamos Luke desenfunda tu sable, demuestra tu ...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>tweet3</td>\n",
              "      <td>- ¬øTe ofrezco algo?, ¬øAgua, caf√©, mi coraz√≥n, ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2.60</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>tweet7</td>\n",
              "      <td>‚ÄîBuenas don Pepe, ¬øme vende un litro de leche?...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.50</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>tweet13</td>\n",
              "      <td>#20CosasQueHacerAntesDeMorir: Ense√±arles la di...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2.60</td>\n",
              "      <td>reference</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>tweet14</td>\n",
              "      <td>Le√≠ que la falta de sexo trae consigo una nota...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3.25</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         id  ... humor_target\n",
              "0    tweet1  ...          NaN\n",
              "1    tweet2  ...          NaN\n",
              "2    tweet3  ...          NaN\n",
              "6    tweet7  ...          NaN\n",
              "12  tweet13  ...          NaN\n",
              "13  tweet14  ...          NaN\n",
              "\n",
              "[6 rows x 12 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oO724yCyKWja"
      },
      "source": [
        "x_train = train_dataframe['text']\n",
        "y_train = train_dataframe['humor_rating']"
      ],
      "id": "oO724yCyKWja",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2a1a262d-af41-4b0a-a58e-404511e53795"
      },
      "source": [
        "cfg = {}\n",
        "cfg[\"framework\"] = \"tf\"\n",
        "cfg[\"max_length\"] = 256 # 380 caracteros maximo por tweet (Mirar maximo de longitud)\n",
        "cfg[\"transformer_model_name\"] = \"dccuchile/bert-base-spanish-wwm-cased\" # Este es el modelo Bert para Spanish, con mayusculas\n",
        "cfg[\"num_labels\"] = 1"
      ],
      "id": "2a1a262d-af41-4b0a-a58e-404511e53795",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb353e76-024b-420e-bc93-4db2832b1478"
      },
      "source": [
        "# dim dimension del pooling layer de los outputs del encoder en la salida de la ultima capa\n",
        "# https://huggingface.co/transformers/model_doc/distilbert.html\n",
        "# https://huggingface.co/dccuchile/bert-base-spanish-wwm-uncased\n",
        "# dropout es el dropout de las denses de las capas de encoders\n",
        "# seq_classif_dropout es el dropout de la ultima densa ajena a Bert\n",
        "# Reducimos la complejidad del problema, solo tenemos 25000 tweets\n",
        "\n",
        "# cargar el tokenizador, disponible en Transformers\n",
        "cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['transformer_model_name'] )\n",
        "\n",
        "# instanciar y entrenar LabelBinarizer\n",
        "#cfg['label_binarizer'] = preprocessing.LabelBinarizer() # guardar para su posterior uso al decodificar predicciones\n",
        "\n",
        "config_bert = DistilBertConfig(attention_dropout=0.75, dropout=0.75,\n",
        "                               n_heads=2, dim=32, max_position_embeddings=cfg[\"max_length\"],\n",
        "                               n_layers=2, hidden_dim=64, vocab_size=cfg['tokenizer'].vocab_size, output_hidden_states=True)\n",
        "# model = TFDistilBertModel.from_pretrained(cfg[\"transformer_model_name\"], config=config_bert)"
      ],
      "id": "bb353e76-024b-420e-bc93-4db2832b1478",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NG5ZpwHrEiJJ",
        "outputId": "94836e89-ff23-46da-a037-85693b99eaea"
      },
      "source": [
        "cfg['tokenizer'].vocab_size"
      ],
      "id": "NG5ZpwHrEiJJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "31002"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zt6usKj7q0ES"
      },
      "source": [
        "# ML Keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Input, BatchNormalization, LeakyReLU, ReLU, Activation, Dropout, Conv1D, Reshape, Flatten, MaxPooling1D, Lambda, Concatenate\n",
        "from tensorflow.keras.activations import softmax, tanh, sigmoid, gelu\n",
        "from keras.utils import np_utils\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras.models import load_model\n"
      ],
      "id": "zt6usKj7q0ES",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qr_0_onemC0A"
      },
      "source": [
        "class CustomDistilBERTModel():\n",
        "    def __init__(self, cfg, config_bert):\n",
        "\n",
        "          # Configuraciones\n",
        "          self.cgf = cfg\n",
        "          self.config_bert = config_bert\n",
        "          \n",
        "          # Instanciamos DistilBertModel\n",
        "          self.DistilBert = TFDistilBertModel.from_pretrained(self.cgf[\"transformer_model_name\"],\n",
        "                                                      config=self.config_bert)\n",
        "          self.DistilBert_model = None\n",
        "\n",
        "    def custom_activation(self, sigma):\n",
        "      # https://stackoverflow.com/questions/51093691/custom-activation-function-keras-applying-different-activation-to-different-lay\n",
        "      return 4*sigma+1\n",
        "\n",
        "    \"\"\"def custom_activation_shape(self, input_shape):\n",
        "        # Ensure there is rank 4 tensor\n",
        "        assert len(input_shape) == 4\n",
        "        # Ensure the last input component has 5 dimensions\n",
        "        assert input_shape[3] == 5\n",
        "\n",
        "        return input_shape  # Shape is unchanged\"\"\"\n",
        "\n",
        "    def get_model_inputs(self, cfg, data):\n",
        "        encodings = cfg['tokenizer'](data, truncation=True, padding='max_length', max_length=cfg['max_length'], return_tensors=cfg['framework'])\n",
        "        inputs = {'input_ids': encodings['input_ids'],\n",
        "                'attention_mask': encodings['attention_mask']\n",
        "                }\n",
        "        return inputs\n",
        "\n",
        "    def DistilBertNN(self):#, ids, mask):\n",
        "          # https://stackoverflow.com/questions/64156202/add-dense-layer-on-top-of-huggingface-bert-model\n",
        "          # https://stackoverflow.com/questions/63201036/add-additional-layers-to-the-huggingface-transformers\n",
        "          input_ids = Input(shape=(256, ),dtype='int32')\n",
        "          attention_mask = Input(shape=(256, ), dtype='int32')\n",
        "\n",
        "          # https://huggingface.co/transformers/model_doc/distilbert.html#distilbertmodel\n",
        "\n",
        "          output_bert = self.DistilBert(\n",
        "                                    input_ids=input_ids, \n",
        "                                    attention_mask=attention_mask\n",
        "                                    )\n",
        "          \"\"\"\n",
        "          last_hidden_state, 1 tensor\n",
        "          hidden_states, 3 tensores (n_layers = 2 + entrada)\n",
        "          attention = None (en principio)\n",
        "          \"\"\"\n",
        "          output_bert = output_bert['hidden_states']\n",
        "          \"\"\"\n",
        "          (batch_size, longitud_secuencia, profundidad de las capas FF intermedias)\n",
        "          (batch_size, max_position_embeddings, dim=32)\n",
        "          \"\"\"\n",
        "\n",
        "          # Probar tambien sumando\n",
        "          output_bert = Concatenate()(output_bert)\n",
        "          dense = MaxPooling1D(pool_size=4)(output_bert)\n",
        "          dense = Flatten()(dense)\n",
        "          dense = Dense(128)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = LeakyReLU()(dense)\n",
        "          dense = Dropout(0.4)(dense)\n",
        "          dense = Dense(64)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = gelu(dense)\n",
        "          dense = Dropout(0.2)(dense)\n",
        "\n",
        "          dense = Dense(1)(dense)\n",
        "          dense = BatchNormalization()(dense)\n",
        "          dense = sigmoid(dense)\n",
        "          output = Lambda(self.custom_activation, \n",
        "                          output_shape=(None,1))(dense)\n",
        "\n",
        "          ### Output\n",
        "          model = Model([input_ids, attention_mask], output)\n",
        "\n",
        "          ### Cross Entropy y Optimizador Adam\n",
        "          model.compile(optimizer=\"adam\", loss=\"mse\", metrics=['mae', tf.keras.metrics.RootMeanSquaredError()])\n",
        "          model.summary()\n",
        "\n",
        "          self.DistilBert_model = model\n",
        "\n",
        "    def train_model(self, x_train, y_train):\n",
        "        \"\"\"\n",
        "        M√©todo que entrena el modelo.\n",
        "\n",
        "        Args:\n",
        "\n",
        "        * x_train: matriz de dise√±o\n",
        "        * y_train: target codificada\n",
        "        \"\"\"\n",
        "\n",
        "        \"\"\"\n",
        "        tokens + attention_mask\n",
        "        \"\"\"\n",
        "\n",
        "        self.DistilBertNN()\n",
        "\n",
        "        # Creo un conjunto de validaci√≥n con data splitting\n",
        "        x_train, x_val, y_train, y_val = train_test_split(x_train, y_train,\n",
        "                                                          test_size=.15)\n",
        "        \n",
        "        train_inputs = self.get_model_inputs(cfg, x_train.to_list())\n",
        "        val_inputs = self.get_model_inputs(cfg, x_val.to_list())\n",
        "\n",
        "        # obtener tensores correspondientes\n",
        "        train_blabels_t = tf.convert_to_tensor(y_train, dtype='int32')\n",
        "        val_blabels_t = tf.convert_to_tensor(y_val, dtype='int32')\n",
        "\n",
        "        # Instancio el m√©√©todo earlyStopping para no perseverar en el entrenamiento si\n",
        "        # se obtiene una mejora tras una paciencia de 8 iteraciones\n",
        "        \"\"\"earlyStopping = EarlyStopping(monitor='val_accuracy', patience=8, verbose=0, mode='max')\"\"\"\n",
        "\n",
        "        # Creo un guardado del mejor modelo visto hasta el fin del entrenamiento monitorizando\n",
        "        # el val_accuracy\n",
        "        \"\"\"checkpoint = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", save_best_only=True)\"\"\"\n",
        "\n",
        "        # Ajusto el modelo con 50 epocas controladas por earlyStopiing y batch size de 50\n",
        "        self.DistilBert_model.fit([train_inputs['input_ids'], train_inputs['attention_mask']], train_blabels_t, \n",
        "                  batch_size = 32, epochs = 10,\n",
        "                  verbose = 1,\n",
        "                  # callbacks=[earlyStopping, checkpoint],\n",
        "                  validation_data=([val_inputs['input_ids'], val_inputs['attention_mask']], val_blabels_t))\n",
        "        plt.hist(self.DistilBert_model.predict([train_inputs['input_ids'], train_inputs['attention_mask']]))"
      ],
      "id": "qr_0_onemC0A",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjaLpWCc9sPe",
        "outputId": "0f25bde4-59c4-4c81-8569-55083d7b6a23"
      },
      "source": [
        "instancia = CustomDistilBERTModel(cfg, config_bert)"
      ],
      "id": "cjaLpWCc9sPe",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some layers from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased were not used when initializing TFDistilBertModel: ['mlm___cls', 'bert']\n",
            "- This IS expected if you are initializing TFDistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing TFDistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some layers of TFDistilBertModel were not initialized from the model checkpoint at dccuchile/bert-base-spanish-wwm-cased and are newly initialized: ['distilbert']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dXQM5aT4-Sqf",
        "outputId": "3736a4f8-27fa-4ddf-a5e7-65209ea7f801"
      },
      "source": [
        "instancia.train_model(x_train, y_train)"
      ],
      "id": "dXQM5aT4-Sqf",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_89 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "input_90 (InputLayer)           [(None, 256)]        0                                            \n",
            "__________________________________________________________________________________________________\n",
            "tf_distil_bert_model_45 (TFDist TFBaseModelOutput(la 1017408     input_89[0][0]                   \n",
            "                                                                 input_90[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 256, 96)      0           tf_distil_bert_model_45[0][0]    \n",
            "                                                                 tf_distil_bert_model_45[0][1]    \n",
            "                                                                 tf_distil_bert_model_45[0][2]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling1d_19 (MaxPooling1D) (None, 64, 96)       0           concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_19 (Flatten)            (None, 6144)         0           max_pooling1d_19[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "dense_72 (Dense)                (None, 128)          786560      flatten_19[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 128)          512         dense_72[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "leaky_re_lu_23 (LeakyReLU)      (None, 128)          0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_368 (Dropout)           (None, 128)          0           leaky_re_lu_23[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "dense_73 (Dense)                (None, 64)           8256        dropout_368[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 64)           256         dense_73[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.nn.gelu_23 (TFOpLambda)      (None, 64)           0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "dropout_369 (Dropout)           (None, 64)           0           tf.nn.gelu_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "dense_74 (Dense)                (None, 1)            65          dropout_369[0][0]                \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 1)            4           dense_74[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "tf.math.sigmoid_13 (TFOpLambda) (None, 1)            0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "lambda_12 (Lambda)              (None, 1)            0           tf.math.sigmoid_13[0][0]         \n",
            "==================================================================================================\n",
            "Total params: 1,813,061\n",
            "Trainable params: 1,812,675\n",
            "Non-trainable params: 386\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "244/246 [============================>.] - ETA: 0s - loss: 2.6245 - mae: 1.3641 - root_mean_squared_error: 1.6195"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n",
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "246/246 [==============================] - 10s 26ms/step - loss: 2.6218 - mae: 1.3632 - root_mean_squared_error: 1.6187 - val_loss: 1.9709 - val_mae: 1.2247 - val_root_mean_squared_error: 1.4039\n",
            "Epoch 2/10\n",
            "246/246 [==============================] - 5s 20ms/step - loss: 1.8257 - mae: 1.1174 - root_mean_squared_error: 1.3510 - val_loss: 1.1168 - val_mae: 0.9035 - val_root_mean_squared_error: 1.0568\n",
            "Epoch 3/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 1.3248 - mae: 0.9550 - root_mean_squared_error: 1.1505 - val_loss: 1.6580 - val_mae: 1.0889 - val_root_mean_squared_error: 1.2876\n",
            "Epoch 4/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.8616 - mae: 0.7812 - root_mean_squared_error: 0.9281 - val_loss: 1.2182 - val_mae: 0.9602 - val_root_mean_squared_error: 1.1037\n",
            "Epoch 5/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.6500 - mae: 0.6726 - root_mean_squared_error: 0.8060 - val_loss: 0.8746 - val_mae: 0.7944 - val_root_mean_squared_error: 0.9352\n",
            "Epoch 6/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.5098 - mae: 0.5831 - root_mean_squared_error: 0.7139 - val_loss: 0.7233 - val_mae: 0.7122 - val_root_mean_squared_error: 0.8505\n",
            "Epoch 7/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.4312 - mae: 0.5370 - root_mean_squared_error: 0.6566 - val_loss: 0.6359 - val_mae: 0.6666 - val_root_mean_squared_error: 0.7974\n",
            "Epoch 8/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.3682 - mae: 0.5006 - root_mean_squared_error: 0.6067 - val_loss: 0.7050 - val_mae: 0.6991 - val_root_mean_squared_error: 0.8397\n",
            "Epoch 9/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.3323 - mae: 0.4822 - root_mean_squared_error: 0.5764 - val_loss: 0.6735 - val_mae: 0.6881 - val_root_mean_squared_error: 0.8207\n",
            "Epoch 10/10\n",
            "246/246 [==============================] - 5s 19ms/step - loss: 0.2934 - mae: 0.4593 - root_mean_squared_error: 0.5416 - val_loss: 0.7487 - val_mae: 0.7168 - val_root_mean_squared_error: 0.8653\n",
            "WARNING:tensorflow:AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f43d9cb0dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Assign object at 0x7f43dc482210>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
            "WARNING: AutoGraph could not transform <function Model.make_predict_function.<locals>.predict_function at 0x7f43d9cb0dd0> and will run it as-is.\n",
            "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
            "Cause: Unknown node type <gast.gast.Assign object at 0x7f43dc482210>\n",
            "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXpf9znPOPX5"
      },
      "source": [
        ""
      ],
      "id": "kXpf9znPOPX5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPa1EtYlKpgz"
      },
      "source": [
        "---\n",
        "\n",
        "---\n",
        "\n",
        "---"
      ],
      "id": "wPa1EtYlKpgz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6bce9e6a-cb3f-41fe-92f1-c8bc4b3e6c8f"
      },
      "source": [
        "# Tripadvisor, aplicamos regresion sin reducir de 5 puntos a 0 1 2\n",
        "# Cambiar las metricas, MSE\n",
        "\n",
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1Score(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "id": "6bce9e6a-cb3f-41fe-92f1-c8bc4b3e6c8f",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8fdeb09c-dbec-45f8-b77f-11a6b4fae2e1"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n",
        "loss = tf.keras.losses.BinaryCrossentropy(from_logits = True)\n",
        "model.compile(optimizer=optimizer, loss=loss, metrics = [f1Score, 'accuracy'])\n",
        "model.summary()"
      ],
      "id": "8fdeb09c-dbec-45f8-b77f-11a6b4fae2e1",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be5082b3-07a6-436f-b439-d0ad3f3750dc"
      },
      "source": [
        "# Cargamos el tokenizador correspondiente ¬øLematiza?\n",
        "cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['transformer_model_name'] )\n",
        "# Proceso de scikit learn para hacer OHE a 0 1 de la salida\n",
        "cfg['label_binarizer'] = preprocessing.LabelBinarizer()"
      ],
      "id": "be5082b3-07a6-436f-b439-d0ad3f3750dc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8e4d7ef1-fcf9-48d9-b4a6-85d02472691f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "26e94f43-d43f-45cf-db7a-f2a9fd1e6b19"
      },
      "source": [
        "# Empleamos el labelizador\n",
        "cfg['label_binarizer'].fit(train_dataframe[\"is_humor\"])\n",
        "train_blabels = cfg['label_binarizer'].transform(train_dataframe[\"is_humor\"])\n",
        "print(train_blabels)\n",
        "train_blabels_t = tf.convert_to_tensor(train_blabels, dtype='int32')\n",
        "\n",
        "# Clases ligeramente desbalanceadas\n",
        "df_clases = pd.DataFrame(train_blabels)\n",
        "round(df_clases.value_counts()/df_clases.shape[0] * 100, 2)"
      ],
      "id": "8e4d7ef1-fcf9-48d9-b4a6-85d02472691f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[1]\n",
            " [1]\n",
            " [1]\n",
            " ...\n",
            " [0]\n",
            " [0]\n",
            " [1]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    61.45\n",
              "1    38.55\n",
              "dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc6f7705-2002-4901-9537-71fe387e0a72"
      },
      "source": [
        "def get_model_inputs(cfg, data):\n",
        "    encodings = cfg['tokenizer'](data, truncation=True, padding='max_length', max_length=cfg['max_length'], return_tensors=cfg['framework'])\n",
        "    inputs = {'input_ids': encodings['input_ids'],\n",
        "            'attention_mask': encodings['attention_mask']\n",
        "            }\n",
        "    return inputs"
      ],
      "id": "bc6f7705-2002-4901-9537-71fe387e0a72",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "202039e9-4ce6-44f5-bc7b-e5ea691dc7ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17116ec6-2fdf-4d82-b88e-ba23051e0474"
      },
      "source": [
        "# Constriumos la matriz de dise√±o con sus correspondientes Masks\n",
        "train_inputs = get_model_inputs(cfg, train_dataframe[\"text\"].to_list())\n",
        "train_inputs"
      ],
      "id": "202039e9-4ce6-44f5-bc7b-e5ea691dc7ad",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': <tf.Tensor: shape=(24000, 256), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'input_ids': <tf.Tensor: shape=(24000, 256), dtype=int32, numpy=\n",
              " array([[    4, 10682,  1019, ...,     1,     1,     1],\n",
              "        [    4,     3,  1716, ...,     1,     1,     1],\n",
              "        [    4,  1149,  1067, ...,     1,     1,     1],\n",
              "        ...,\n",
              "        [    4,  2448,  1030, ...,     1,     1,     1],\n",
              "        [    4,  4596,  1512, ...,     1,     1,     1],\n",
              "        [    4,  1153,  8386, ...,     1,     1,     1]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7hscjN2B00J",
        "outputId": "0f2ede5c-7ad8-4c78-bef8-f8c7bd0c2d1d"
      },
      "source": [
        "print(cfg['tokenizer'].pad_token)\n",
        "cfg['tokenizer'].encode([cfg['tokenizer'].pad_token])"
      ],
      "id": "i7hscjN2B00J",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[PAD]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 1, 5]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ZiLusmOUCYlJ",
        "outputId": "733b81df-81a7-430d-dc5c-8e6ac0ab5b6a"
      },
      "source": [
        "cfg['tokenizer'].decode([4, 1, 5])"
      ],
      "id": "ZiLusmOUCYlJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'[CLS] [PAD] [SEP]'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9ec284c-fc4e-4629-9e7e-8aa68adcfdbc"
      },
      "source": [
        "cfg['checkpoints_dir'] = 'checkpoints'\n",
        "cfg['model_name'] = 'distilbert-humor'\n",
        "cfg['trained_model_name'] = os.path.join(cfg['checkpoints_dir'], cfg['model_name'])"
      ],
      "id": "b9ec284c-fc4e-4629-9e7e-8aa68adcfdbc",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C69ozX5-MndC"
      },
      "source": [
        "tlabels = train_blabels.reshape(train_blabels.shape[0])"
      ],
      "id": "C69ozX5-MndC",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_wT5fC8pzSI",
        "outputId": "14b96e21-b809-465f-83bb-b30afe8c4b7e"
      },
      "source": [
        "train_inputs"
      ],
      "id": "M_wT5fC8pzSI",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': <tf.Tensor: shape=(24000, 256), dtype=int32, numpy=\n",
              " array([[1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0],\n",
              "        [1, 1, 1, ..., 0, 0, 0]], dtype=int32)>,\n",
              " 'input_ids': <tf.Tensor: shape=(24000, 256), dtype=int32, numpy=\n",
              " array([[    4, 10682,  1019, ...,     1,     1,     1],\n",
              "        [    4,     3,  1716, ...,     1,     1,     1],\n",
              "        [    4,  1149,  1067, ...,     1,     1,     1],\n",
              "        ...,\n",
              "        [    4,  2448,  1030, ...,     1,     1,     1],\n",
              "        [    4,  4596,  1512, ...,     1,     1,     1],\n",
              "        [    4,  1153,  8386, ...,     1,     1,     1]], dtype=int32)>}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4294efd-f1d1-4d95-ae3b-f533bd1c1850",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e751556a-aa03-45a0-8339-f8a58a7253ff"
      },
      "source": [
        "epochs_max = 30\n",
        "epochs_to_save = 5\n",
        "batch_size = 32\n",
        "\n",
        "class_weights = class_weight.compute_class_weight('balanced', np.unique(tlabels), tlabels)\n",
        "class_weights = dict(enumerate(class_weights))\n",
        "\n",
        "for epoch in tqdm.tqdm(range(0, epochs_max, epochs_to_save)):\n",
        "    print(f'Training model, epochs {epoch+1} - {epoch+epochs_to_save}')\n",
        "    \n",
        "    # entrenar el modelo. Opcionalmente, se puede suministrar datos de validaci√≥n => validation_data=(val_inputs,val_blabels_t )\n",
        "    model.fit(train_inputs, y=train_blabels_t, epochs=epochs_to_save, batch_size=batch_size,\n",
        "              validation_split=0.25, class_weight=class_weights)\n",
        "\n",
        "    model.save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch+1:03d}-{epoch+epochs_to_save:03d}')\n",
        "    cfg['tokenizer'].save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch+1:03d}-{epoch+epochs_to_save:03d}')"
      ],
      "id": "d4294efd-f1d1-4d95-ae3b-f533bd1c1850",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "  0%|          | 0/6 [00:00<?, ?it/s]\u001b[AThe parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model, epochs 1 - 5\n",
            "Epoch 1/5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "562/563 [============================>.] - ETA: 0s - loss: 0.6768 - f1Score: 0.0000e+00 - accuracy: 0.6615"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "The parameters `output_attentions`, `output_hidden_states` and `use_cache` cannot be updated when calling a model.They have to be set to True/False in the config object (i.e.: `config=XConfig.from_pretrained('name', output_attentions=True)`).\n",
            "The parameter `return_dict` cannot be set in graph mode and will always be set to `True`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "563/563 [==============================] - 5s 10ms/step - loss: 0.6769 - f1Score: 0.0000e+00 - accuracy: 0.6614 - val_loss: 0.6940 - val_f1Score: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.6756 - f1Score: 0.0000e+00 - accuracy: 0.6614 - val_loss: 0.6955 - val_f1Score: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.6714 - f1Score: 0.0000e+00 - accuracy: 0.6614 - val_loss: 0.6856 - val_f1Score: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.6433 - f1Score: 0.0000e+00 - accuracy: 0.6614 - val_loss: 0.6498 - val_f1Score: 0.0000e+00 - val_accuracy: 0.4737\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.6011 - f1Score: 0.0000e+00 - accuracy: 0.6614 - val_loss: 0.6145 - val_f1Score: 0.0000e+00 - val_accuracy: 0.4737\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 17%|‚ñà‚ñã        | 1/6 [00:27<02:18, 27.76s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model, epochs 6 - 10\n",
            "Epoch 1/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.5613 - f1Score: 0.2043 - accuracy: 0.6913 - val_loss: 0.5867 - val_f1Score: 0.6174 - val_accuracy: 0.6935\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.5309 - f1Score: 0.5038 - accuracy: 0.7434 - val_loss: 0.5632 - val_f1Score: 0.7190 - val_accuracy: 0.7402\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.5045 - f1Score: 0.6373 - accuracy: 0.7830 - val_loss: 0.5423 - val_f1Score: 0.7325 - val_accuracy: 0.7542\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4851 - f1Score: 0.6566 - accuracy: 0.7892 - val_loss: 0.5313 - val_f1Score: 0.7291 - val_accuracy: 0.7572\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4672 - f1Score: 0.6714 - accuracy: 0.7967 - val_loss: 0.5173 - val_f1Score: 0.7432 - val_accuracy: 0.7670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 33%|‚ñà‚ñà‚ñà‚ñé      | 2/6 [00:53<01:48, 27.09s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model, epochs 11 - 15\n",
            "Epoch 1/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4514 - f1Score: 0.7006 - accuracy: 0.8131 - val_loss: 0.5070 - val_f1Score: 0.7540 - val_accuracy: 0.7733\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4434 - f1Score: 0.7126 - accuracy: 0.8153 - val_loss: 0.5014 - val_f1Score: 0.7606 - val_accuracy: 0.7752\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4333 - f1Score: 0.7254 - accuracy: 0.8234 - val_loss: 0.4978 - val_f1Score: 0.7572 - val_accuracy: 0.7767\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4245 - f1Score: 0.7338 - accuracy: 0.8280 - val_loss: 0.4958 - val_f1Score: 0.7641 - val_accuracy: 0.7788\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4185 - f1Score: 0.7386 - accuracy: 0.8321 - val_loss: 0.4902 - val_f1Score: 0.7631 - val_accuracy: 0.7798\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 3/6 [01:18<01:19, 26.58s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model, epochs 16 - 20\n",
            "Epoch 1/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4123 - f1Score: 0.7462 - accuracy: 0.8366 - val_loss: 0.4860 - val_f1Score: 0.7642 - val_accuracy: 0.7788\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.4031 - f1Score: 0.7468 - accuracy: 0.8398 - val_loss: 0.4871 - val_f1Score: 0.7666 - val_accuracy: 0.7813\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3957 - f1Score: 0.7541 - accuracy: 0.8429 - val_loss: 0.4914 - val_f1Score: 0.7595 - val_accuracy: 0.7783\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3898 - f1Score: 0.7651 - accuracy: 0.8486 - val_loss: 0.4859 - val_f1Score: 0.7607 - val_accuracy: 0.7778\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3821 - f1Score: 0.7635 - accuracy: 0.8488 - val_loss: 0.4839 - val_f1Score: 0.7644 - val_accuracy: 0.7802\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 67%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã   | 4/6 [01:44<00:52, 26.28s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model, epochs 21 - 25\n",
            "Epoch 1/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3784 - f1Score: 0.7661 - accuracy: 0.8511 - val_loss: 0.4852 - val_f1Score: 0.7611 - val_accuracy: 0.7795\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3764 - f1Score: 0.7698 - accuracy: 0.8521 - val_loss: 0.4872 - val_f1Score: 0.7582 - val_accuracy: 0.7790\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3670 - f1Score: 0.7763 - accuracy: 0.8572 - val_loss: 0.4868 - val_f1Score: 0.7654 - val_accuracy: 0.7802\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3663 - f1Score: 0.7803 - accuracy: 0.8591 - val_loss: 0.4921 - val_f1Score: 0.7584 - val_accuracy: 0.7787\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3609 - f1Score: 0.7760 - accuracy: 0.8573 - val_loss: 0.4891 - val_f1Score: 0.7674 - val_accuracy: 0.7820\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            " 83%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé | 5/6 [02:09<00:25, 25.96s/it]\u001b[A"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training model, epochs 26 - 30\n",
            "Epoch 1/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3573 - f1Score: 0.7838 - accuracy: 0.8620 - val_loss: 0.4895 - val_f1Score: 0.7691 - val_accuracy: 0.7837\n",
            "Epoch 2/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3528 - f1Score: 0.7911 - accuracy: 0.8647 - val_loss: 0.4951 - val_f1Score: 0.7584 - val_accuracy: 0.7793\n",
            "Epoch 3/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3501 - f1Score: 0.7898 - accuracy: 0.8652 - val_loss: 0.4921 - val_f1Score: 0.7647 - val_accuracy: 0.7830\n",
            "Epoch 4/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3508 - f1Score: 0.7900 - accuracy: 0.8649 - val_loss: 0.4955 - val_f1Score: 0.7607 - val_accuracy: 0.7817\n",
            "Epoch 5/5\n",
            "563/563 [==============================] - 5s 9ms/step - loss: 0.3445 - f1Score: 0.7924 - accuracy: 0.8671 - val_loss: 0.4902 - val_f1Score: 0.7669 - val_accuracy: 0.7860\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 6/6 [02:34<00:00, 25.83s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jr5vdNWQHjk8"
      },
      "source": [
        ""
      ],
      "id": "jr5vdNWQHjk8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0SuB4gDlld8"
      },
      "source": [
        "# Regresion"
      ],
      "id": "R0SuB4gDlld8"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "peXyKBkBlmrA"
      },
      "source": [
        "from transformers import BertModel\n",
        "class CustomBERTModel(nn.Module):\n",
        "    def __init__(self):\n",
        "          super(CustomBERTModel, self).__init__()\n",
        "          self.bert = BertModel.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\")\n",
        "          ### New layers:\n",
        "          self.linear1 = nn.Linear(768, 256)\n",
        "          self.linear2 = nn.Linear(256, 3) ## 3 is the number of classes in this example\n",
        "\n",
        "    def forward(self, ids, mask):\n",
        "          sequence_output, pooled_output = self.bert(\n",
        "               ids, \n",
        "               attention_mask=mask)\n",
        "\n",
        "          # sequence_output has the following shape: (batch_size, sequence_length, 768)\n",
        "          linear1_output = self.linear1(sequence_output[:,0,:].view(-1,768)) ## extract the 1st token's embeddings\n",
        "\n",
        "          linear2_output = self.linear2(linear2_output)\n",
        "\n",
        "          return linear2_output\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"dbmdz/bert-base-italian-xxl-cased\")\n",
        "model = CustomBERTModel() # You can pass the parameters if required to have more flexible model\n",
        "model.to(torch.device(\"cpu\")) ## can be gpu\n",
        "criterion = nn.CrossEntropyLoss() ## If required define your own criterion\n",
        "optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, model.parameters()))\n",
        "\n",
        "for epoch in epochs:\n",
        "    for batch in data_loader: ## If you have a DataLoader()  object to get the data.\n",
        "\n",
        "        data = batch[0]\n",
        "        targets = batch[1] ## assuming that data loader returns a tuple of data and its targets\n",
        "        \n",
        "        optimizer.zero_grad()   \n",
        "        encoding = tokenizer.batch_encode_plus(data, return_tensors='pt', padding=True, truncation=True,max_length=50, add_special_tokens = True)\n",
        "        outputs = model(input_ids, attention_mask=attention_mask)\n",
        "        outputs = F.log_softmax(outputs, dim=1)\n",
        "        input_ids = encoding['input_ids']\n",
        "        attention_mask = encoding['attention_mask']\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "id": "peXyKBkBlmrA",
      "execution_count": null,
      "outputs": []
    }
  ]
}